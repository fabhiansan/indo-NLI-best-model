{
  "indo-roberta": {
    "validation": {
      "accuracy": 0.7173418297678653,
      "precision": 0.717545643282732,
      "recall": 0.7145291319202695,
      "f1": 0.7151062078377001,
      "precision_entailment": 0.7096399535423926,
      "recall_entailment": 0.7571251548946716,
      "f1_entailment": 0.7326139088729017,
      "precision_neutral": 0.661608497723824,
      "recall_neutral": 0.6801872074882995,
      "f1_neutral": 0.6707692307692308,
      "precision_contradiction": 0.7813884785819794,
      "recall_contradiction": 0.7062750333778371,
      "f1_contradiction": 0.7419354838709677
    },
    "test_lay": {
      "accuracy": 0.7155838255338483,
      "precision": 0.71463009349131,
      "recall": 0.7151036298246062,
      "f1": 0.7140164196744924,
      "precision_entailment": 0.7230955259975816,
      "recall_entailment": 0.7400990099009901,
      "f1_entailment": 0.7314984709480122,
      "precision_neutral": 0.6646971935007385,
      "recall_neutral": 0.7154213036565977,
      "f1_neutral": 0.6891271056661562,
      "precision_contradiction": 0.7560975609756098,
      "recall_contradiction": 0.6897905759162304,
      "f1_contradiction": 0.7214236824093087
    },
    "test_expert": {
      "accuracy": 0.5640080428954424,
      "precision": 0.5775520813634634,
      "recall": 0.5699641479510087,
      "f1": 0.5555342752120023,
      "precision_entailment": 0.5724465558194775,
      "recall_entailment": 0.46301633045148893,
      "f1_entailment": 0.5119490175252257,
      "precision_neutral": 0.5260989010989011,
      "recall_neutral": 0.8114406779661016,
      "f1_neutral": 0.6383333333333333,
      "precision_contradiction": 0.6341107871720116,
      "recall_contradiction": 0.43543543543543545,
      "f1_contradiction": 0.516320474777448
    }
  },
  "indo-roberta-base": {
    "validation": {
      "accuracy": 0.7637687756030951,
      "precision": 0.7615583044305518,
      "recall": 0.7606979985593575,
      "f1": 0.760999106025532,
      "precision_entailment": 0.7681159420289855,
      "recall_entailment": 0.7881040892193308,
      "f1_entailment": 0.7779816513761468,
      "precision_neutral": 0.7074303405572755,
      "recall_neutral": 0.7129485179407177,
      "f1_neutral": 0.7101787101787101,
      "precision_contradiction": 0.8091286307053942,
      "recall_contradiction": 0.7810413885180241,
      "f1_contradiction": 0.7948369565217391
    },
    "test_lay": {
      "accuracy": 0.7346660608814175,
      "precision": 0.7321613360305537,
      "recall": 0.7320865260391312,
      "f1": 0.7316540716659382,
      "precision_entailment": 0.7512135922330098,
      "recall_entailment": 0.7660891089108911,
      "f1_entailment": 0.758578431372549,
      "precision_neutral": 0.665158371040724,
      "recall_neutral": 0.7011128775834659,
      "f1_neutral": 0.6826625386996904,
      "precision_contradiction": 0.7801120448179272,
      "recall_contradiction": 0.7290575916230366,
      "f1_contradiction": 0.7537212449255751
    },
    "test_expert": {
      "accuracy": 0.596514745308311,
      "precision": 0.6188813378868028,
      "recall": 0.6023446831696315,
      "f1": 0.5898504739074916,
      "precision_entailment": 0.616945107398568,
      "recall_entailment": 0.4966378482228626,
      "f1_entailment": 0.5502927088877062,
      "precision_neutral": 0.536271186440678,
      "recall_neutral": 0.8379237288135594,
      "f1_neutral": 0.6539892517569244,
      "precision_contradiction": 0.7034277198211625,
      "recall_contradiction": 0.4724724724724725,
      "f1_contradiction": 0.5652694610778443
    }
  },
  "indo-roberta-base-checkpoint-500": {
    "validation": {
      "accuracy": 0.0,
      "f1": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "error": "No pretrained_model_name.txt found at models/indo-roberta-base/checkpoint-500/pretrained_model_name.txt. Cannot load model."
    },
    "test_lay": {
      "accuracy": 0.0,
      "f1": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "error": "No pretrained_model_name.txt found at models/indo-roberta-base/checkpoint-500/pretrained_model_name.txt. Cannot load model."
    },
    "test_expert": {
      "accuracy": 0.0,
      "f1": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "error": "No pretrained_model_name.txt found at models/indo-roberta-base/checkpoint-500/pretrained_model_name.txt. Cannot load model."
    }
  },
  "indo-roberta-base-epoch-1": {
    "validation": {
      "accuracy": 0.6677287209831588,
      "precision": 0.6705520710280481,
      "recall": 0.664461082739,
      "f1": 0.665999224307336,
      "precision_entailment": 0.6395089285714286,
      "recall_entailment": 0.7100371747211895,
      "f1_entailment": 0.6729301233118027,
      "precision_neutral": 0.6244131455399061,
      "recall_neutral": 0.6224648985959438,
      "f1_neutral": 0.6234375,
      "precision_contradiction": 0.7477341389728097,
      "recall_contradiction": 0.6608811748998665,
      "f1_contradiction": 0.7016300496102055
    },
    "test_lay": {
      "accuracy": 0.6401635620172649,
      "precision": 0.6421060603393108,
      "recall": 0.6374058753231303,
      "f1": 0.6380742326211332,
      "precision_entailment": 0.6245694603903559,
      "recall_entailment": 0.6732673267326733,
      "f1_entailment": 0.6480047647409172,
      "precision_neutral": 0.5680119581464873,
      "recall_neutral": 0.604133545310016,
      "f1_neutral": 0.5855161787365177,
      "precision_contradiction": 0.7337367624810892,
      "recall_contradiction": 0.6348167539267016,
      "f1_contradiction": 0.6807017543859649
    },
    "test_expert": {
      "accuracy": 0.49932975871313673,
      "precision": 0.5205778847161022,
      "recall": 0.5053871562342068,
      "f1": 0.4879548440896624,
      "precision_entailment": 0.4976635514018692,
      "recall_entailment": 0.4092219020172911,
      "f1_entailment": 0.44913020558777017,
      "precision_neutral": 0.4623309723116549,
      "recall_neutral": 0.760593220338983,
      "f1_neutral": 0.5750901081297557,
      "precision_contradiction": 0.6017391304347826,
      "recall_contradiction": 0.34634634634634637,
      "f1_contradiction": 0.43964421855146124
    }
  },
  "indo-roberta-base-epoch-2": {
    "validation": {
      "accuracy": 0.7373691397360036,
      "precision": 0.7420113760813835,
      "recall": 0.7323945985833801,
      "f1": 0.7336061312590862,
      "precision_entailment": 0.7133689839572193,
      "recall_entailment": 0.8265179677819083,
      "f1_entailment": 0.7657864523536165,
      "precision_neutral": 0.6817472698907956,
      "recall_neutral": 0.6817472698907956,
      "f1_neutral": 0.6817472698907956,
      "precision_contradiction": 0.8309178743961353,
      "recall_contradiction": 0.6889185580774366,
      "f1_contradiction": 0.7532846715328467
    },
    "test_lay": {
      "accuracy": 0.7187641980917765,
      "precision": 0.723669718053297,
      "recall": 0.715074589617961,
      "f1": 0.715613074111424,
      "precision_entailment": 0.6920600858369099,
      "recall_entailment": 0.7982673267326733,
      "f1_entailment": 0.7413793103448276,
      "precision_neutral": 0.6661490683229814,
      "recall_neutral": 0.6820349761526232,
      "f1_neutral": 0.6739984289080911,
      "precision_contradiction": 0.8128,
      "recall_contradiction": 0.6649214659685864,
      "f1_contradiction": 0.7314614830813535
    },
    "test_expert": {
      "accuracy": 0.561662198391421,
      "precision": 0.5956620548267929,
      "recall": 0.5660176348053878,
      "f1": 0.5518822996764666,
      "precision_entailment": 0.5467695274831244,
      "recall_entailment": 0.5446685878962536,
      "f1_entailment": 0.5457170356111646,
      "precision_neutral": 0.5149201943095073,
      "recall_neutral": 0.7860169491525424,
      "f1_neutral": 0.6222222222222222,
      "precision_contradiction": 0.7252964426877471,
      "recall_contradiction": 0.36736736736736736,
      "f1_contradiction": 0.4877076411960133
    }
  },
  "indo-roberta-base-epoch-3": {
    "validation": {
      "accuracy": 0.7537551206190259,
      "precision": 0.7556471192902223,
      "recall": 0.7544381729872027,
      "f1": 0.7527418865768679,
      "precision_entailment": 0.7891332470892626,
      "recall_entailment": 0.7558859975216853,
      "f1_entailment": 0.7721518987341772,
      "precision_neutral": 0.6573333333333333,
      "recall_neutral": 0.7691107644305772,
      "f1_neutral": 0.7088425593098491,
      "precision_contradiction": 0.8204747774480712,
      "recall_contradiction": 0.7383177570093458,
      "f1_contradiction": 0.7772312016865777
    },
    "test_lay": {
      "accuracy": 0.7310313493866424,
      "precision": 0.7353097514214371,
      "recall": 0.7333145075051543,
      "f1": 0.7302911430484023,
      "precision_entailment": 0.7749667110519307,
      "recall_entailment": 0.7202970297029703,
      "f1_entailment": 0.7466324567030147,
      "precision_neutral": 0.6187419768934531,
      "recall_neutral": 0.766295707472178,
      "f1_neutral": 0.6846590909090909,
      "precision_contradiction": 0.812220566318927,
      "recall_contradiction": 0.7133507853403142,
      "f1_contradiction": 0.759581881533101
    },
    "test_expert": {
      "accuracy": 0.5626675603217158,
      "precision": 0.6076063931937375,
      "recall": 0.5700741751047845,
      "f1": 0.5523016300800648,
      "precision_entailment": 0.5983827493261455,
      "recall_entailment": 0.4265129682997118,
      "f1_entailment": 0.49803701626472235,
      "precision_neutral": 0.48713345302214245,
      "recall_neutral": 0.8622881355932204,
      "f1_neutral": 0.6225621414913958,
      "precision_contradiction": 0.7373029772329247,
      "recall_contradiction": 0.4214214214214214,
      "f1_contradiction": 0.5363057324840764
    }
  },
  "indo-roberta-base-epoch-4": {
    "validation": {
      "accuracy": 0.7692307692307693,
      "precision": 0.7679585159052477,
      "recall": 0.76541971822592,
      "f1": 0.7662329205700505,
      "precision_entailment": 0.7628504672897196,
      "recall_entailment": 0.8091697645600991,
      "f1_entailment": 0.7853277209861695,
      "precision_neutral": 0.7192429022082019,
      "recall_neutral": 0.7113884555382215,
      "f1_neutral": 0.7152941176470589,
      "precision_contradiction": 0.8217821782178217,
      "recall_contradiction": 0.7757009345794392,
      "f1_contradiction": 0.7980769230769231
    },
    "test_lay": {
      "accuracy": 0.7346660608814175,
      "precision": 0.7323284771380897,
      "recall": 0.7309810099780735,
      "f1": 0.731032733325338,
      "precision_entailment": 0.7423887587822015,
      "recall_entailment": 0.7846534653465347,
      "f1_entailment": 0.762936221419976,
      "precision_neutral": 0.6744548286604362,
      "recall_neutral": 0.6883942766295708,
      "f1_neutral": 0.6813532651455547,
      "precision_contradiction": 0.7801418439716312,
      "recall_contradiction": 0.7198952879581152,
      "f1_contradiction": 0.7488087134104833
    },
    "test_expert": {
      "accuracy": 0.5934986595174263,
      "precision": 0.616182212078538,
      "recall": 0.5987868118937087,
      "f1": 0.5871539943832257,
      "precision_entailment": 0.6031390134529148,
      "recall_entailment": 0.5168107588856868,
      "f1_entailment": 0.5566476978789446,
      "precision_neutral": 0.5362318840579711,
      "recall_neutral": 0.823093220338983,
      "f1_neutral": 0.6493940660259089,
      "precision_contradiction": 0.7091757387247278,
      "recall_contradiction": 0.45645645645645644,
      "f1_contradiction": 0.5554202192448234
    }
  },
  "indo-roberta-base-epoch-5": {
    "validation": {
      "accuracy": 0.7637687756030951,
      "precision": 0.7615583044305518,
      "recall": 0.7606979985593575,
      "f1": 0.760999106025532,
      "precision_entailment": 0.7681159420289855,
      "recall_entailment": 0.7881040892193308,
      "f1_entailment": 0.7779816513761468,
      "precision_neutral": 0.7074303405572755,
      "recall_neutral": 0.7129485179407177,
      "f1_neutral": 0.7101787101787101,
      "precision_contradiction": 0.8091286307053942,
      "recall_contradiction": 0.7810413885180241,
      "f1_contradiction": 0.7948369565217391
    },
    "test_lay": {
      "accuracy": 0.7346660608814175,
      "precision": 0.7321613360305537,
      "recall": 0.7320865260391312,
      "f1": 0.7316540716659382,
      "precision_entailment": 0.7512135922330098,
      "recall_entailment": 0.7660891089108911,
      "f1_entailment": 0.758578431372549,
      "precision_neutral": 0.665158371040724,
      "recall_neutral": 0.7011128775834659,
      "f1_neutral": 0.6826625386996904,
      "precision_contradiction": 0.7801120448179272,
      "recall_contradiction": 0.7290575916230366,
      "f1_contradiction": 0.7537212449255751
    },
    "test_expert": {
      "accuracy": 0.596514745308311,
      "precision": 0.6188813378868028,
      "recall": 0.6023446831696315,
      "f1": 0.5898504739074916,
      "precision_entailment": 0.616945107398568,
      "recall_entailment": 0.4966378482228626,
      "f1_entailment": 0.5502927088877062,
      "precision_neutral": 0.536271186440678,
      "recall_neutral": 0.8379237288135594,
      "f1_neutral": 0.6539892517569244,
      "precision_contradiction": 0.7034277198211625,
      "recall_contradiction": 0.4724724724724725,
      "f1_contradiction": 0.5652694610778443
    }
  },
  "indo-roberta-epoch-1": {
    "validation": {
      "accuracy": 0.6841147018661812,
      "precision": 0.6984190819704789,
      "recall": 0.6743155226413377,
      "f1": 0.6772360783759742,
      "precision_entailment": 0.6261770244821092,
      "recall_entailment": 0.8240396530359355,
      "f1_entailment": 0.7116104868913857,
      "precision_neutral": 0.6617100371747212,
      "recall_neutral": 0.5553822152886115,
      "f1_neutral": 0.6039016115351993,
      "precision_contradiction": 0.8073701842546064,
      "recall_contradiction": 0.6435246995994659,
      "f1_contradiction": 0.7161961367013373
    },
    "test_lay": {
      "accuracy": 0.6742389822807815,
      "precision": 0.6859194967812664,
      "recall": 0.6647517849030593,
      "f1": 0.6670318170667621,
      "precision_entailment": 0.6223908918406073,
      "recall_entailment": 0.8118811881188119,
      "f1_entailment": 0.7046186895810956,
      "precision_neutral": 0.6610169491525424,
      "recall_neutral": 0.5580286168521462,
      "f1_neutral": 0.6051724137931035,
      "precision_contradiction": 0.7743506493506493,
      "recall_contradiction": 0.6243455497382199,
      "f1_contradiction": 0.691304347826087
    },
    "test_expert": {
      "accuracy": 0.5204423592493298,
      "precision": 0.5368307896401884,
      "recall": 0.5237997658757115,
      "f1": 0.5113186467750809,
      "precision_entailment": 0.4807355516637478,
      "recall_entailment": 0.5273775216138329,
      "f1_entailment": 0.5029775538250114,
      "precision_neutral": 0.5162037037037037,
      "recall_neutral": 0.7086864406779662,
      "f1_neutral": 0.5973214285714286,
      "precision_contradiction": 0.6135531135531136,
      "recall_contradiction": 0.3353353353353353,
      "f1_contradiction": 0.4336569579288026
    }
  },
  "indo-roberta-epoch-2": {
    "validation": {
      "accuracy": 0.7096040054619936,
      "precision": 0.7176339903789426,
      "recall": 0.7052881860163502,
      "f1": 0.7057456111809923,
      "precision_entailment": 0.6848167539267016,
      "recall_entailment": 0.8104089219330854,
      "f1_entailment": 0.7423382519863791,
      "precision_neutral": 0.6525679758308157,
      "recall_neutral": 0.6739469578783152,
      "f1_neutral": 0.6630851880276285,
      "precision_contradiction": 0.8155172413793104,
      "recall_contradiction": 0.6315086782376502,
      "f1_contradiction": 0.7118133935289691
    },
    "test_lay": {
      "accuracy": 0.7069513857337574,
      "precision": 0.7154914412043386,
      "recall": 0.7045763471668419,
      "f1": 0.7045498642347144,
      "precision_entailment": 0.6733615221987315,
      "recall_entailment": 0.7883663366336634,
      "f1_entailment": 0.7263397947548461,
      "precision_neutral": 0.6586102719033232,
      "recall_neutral": 0.6931637519872814,
      "f1_neutral": 0.675445391169636,
      "precision_contradiction": 0.8145025295109612,
      "recall_contradiction": 0.6321989528795812,
      "f1_contradiction": 0.711864406779661
    },
    "test_expert": {
      "accuracy": 0.5495978552278821,
      "precision": 0.5716120812613387,
      "recall": 0.553725974179132,
      "f1": 0.5378074217046233,
      "precision_entailment": 0.5224977043158862,
      "recall_entailment": 0.5465898174831892,
      "f1_entailment": 0.5342723004694836,
      "precision_neutral": 0.5282608695652173,
      "recall_neutral": 0.7722457627118644,
      "f1_neutral": 0.6273666092943201,
      "precision_contradiction": 0.6640776699029126,
      "recall_contradiction": 0.34234234234234234,
      "f1_contradiction": 0.45178335535006603
    }
  },
  "indo-roberta-epoch-3": {
    "validation": {
      "accuracy": 0.7068730086481566,
      "precision": 0.7162174595337784,
      "recall": 0.7112671773164024,
      "f1": 0.7072183368067337,
      "precision_entailment": 0.7702127659574468,
      "recall_entailment": 0.6728624535315985,
      "f1_entailment": 0.7182539682539683,
      "precision_neutral": 0.5938242280285035,
      "recall_neutral": 0.7800312012480499,
      "f1_neutral": 0.6743088334457181,
      "precision_contradiction": 0.7846153846153846,
      "recall_contradiction": 0.6809078771695594,
      "f1_contradiction": 0.7290922087205146
    },
    "test_lay": {
      "accuracy": 0.6996819627442071,
      "precision": 0.7091984435462696,
      "recall": 0.7066227734777074,
      "f1": 0.6999080286038293,
      "precision_entailment": 0.7557142857142857,
      "recall_entailment": 0.6547029702970297,
      "f1_entailment": 0.7015915119363395,
      "precision_neutral": 0.5934195064629847,
      "recall_neutral": 0.8028616852146264,
      "f1_neutral": 0.6824324324324325,
      "precision_contradiction": 0.7784615384615384,
      "recall_contradiction": 0.662303664921466,
      "f1_contradiction": 0.7157001414427157
    },
    "test_expert": {
      "accuracy": 0.542225201072386,
      "precision": 0.5758412730830691,
      "recall": 0.5504145374065513,
      "f1": 0.5281628614687801,
      "precision_entailment": 0.5827123695976155,
      "recall_entailment": 0.3756003842459174,
      "f1_entailment": 0.4567757009345794,
      "precision_neutral": 0.48134991119005327,
      "recall_neutral": 0.861228813559322,
      "f1_neutral": 0.6175465248765667,
      "precision_contradiction": 0.6634615384615384,
      "recall_contradiction": 0.4144144144144144,
      "f1_contradiction": 0.5101663585951941
    }
  },
  "indo-roberta-epoch-4": {
    "validation": {
      "accuracy": 0.7159763313609467,
      "precision": 0.7174399380564148,
      "recall": 0.7140078189028961,
      "f1": 0.7141434901464189,
      "precision_entailment": 0.712280701754386,
      "recall_entailment": 0.7546468401486989,
      "f1_entailment": 0.7328519855595668,
      "precision_neutral": 0.6491994177583698,
      "recall_neutral": 0.6957878315132605,
      "f1_neutral": 0.6716867469879518,
      "precision_contradiction": 0.7908396946564885,
      "recall_contradiction": 0.6915887850467289,
      "f1_contradiction": 0.7378917378917379
    },
    "test_lay": {
      "accuracy": 0.7110404361653794,
      "precision": 0.7123668051533679,
      "recall": 0.7114436366434402,
      "f1": 0.7097467773302751,
      "precision_entailment": 0.7137724550898203,
      "recall_entailment": 0.7376237623762376,
      "f1_entailment": 0.7255021302495435,
      "precision_neutral": 0.6463932107496464,
      "recall_neutral": 0.7265500794912559,
      "f1_neutral": 0.6841317365269461,
      "precision_contradiction": 0.7769347496206374,
      "recall_contradiction": 0.6701570680628273,
      "f1_contradiction": 0.7196064652143359
    },
    "test_expert": {
      "accuracy": 0.5546246648793566,
      "precision": 0.5778156312923047,
      "recall": 0.561089589524398,
      "f1": 0.5444486313228053,
      "precision_entailment": 0.5738916256157636,
      "recall_entailment": 0.44764649375600385,
      "f1_entailment": 0.5029681597409607,
      "precision_neutral": 0.5035552682611506,
      "recall_neutral": 0.8252118644067796,
      "f1_neutral": 0.625451625853071,
      "precision_contradiction": 0.656,
      "recall_contradiction": 0.41041041041041043,
      "f1_contradiction": 0.5049261083743842
    }
  },
  "indo-roberta-epoch-5": {
    "validation": {
      "accuracy": 0.7173418297678653,
      "precision": 0.717545643282732,
      "recall": 0.7145291319202695,
      "f1": 0.7151062078377001,
      "precision_entailment": 0.7096399535423926,
      "recall_entailment": 0.7571251548946716,
      "f1_entailment": 0.7326139088729017,
      "precision_neutral": 0.661608497723824,
      "recall_neutral": 0.6801872074882995,
      "f1_neutral": 0.6707692307692308,
      "precision_contradiction": 0.7813884785819794,
      "recall_contradiction": 0.7062750333778371,
      "f1_contradiction": 0.7419354838709677
    },
    "test_lay": {
      "accuracy": 0.7155838255338483,
      "precision": 0.71463009349131,
      "recall": 0.7151036298246062,
      "f1": 0.7140164196744924,
      "precision_entailment": 0.7230955259975816,
      "recall_entailment": 0.7400990099009901,
      "f1_entailment": 0.7314984709480122,
      "precision_neutral": 0.6646971935007385,
      "recall_neutral": 0.7154213036565977,
      "f1_neutral": 0.6891271056661562,
      "precision_contradiction": 0.7560975609756098,
      "recall_contradiction": 0.6897905759162304,
      "f1_contradiction": 0.7214236824093087
    },
    "test_expert": {
      "accuracy": 0.5640080428954424,
      "precision": 0.5775520813634634,
      "recall": 0.5699641479510087,
      "f1": 0.5555342752120023,
      "precision_entailment": 0.5724465558194775,
      "recall_entailment": 0.46301633045148893,
      "f1_entailment": 0.5119490175252257,
      "precision_neutral": 0.5260989010989011,
      "recall_neutral": 0.8114406779661016,
      "f1_neutral": 0.6383333333333333,
      "precision_contradiction": 0.6341107871720116,
      "recall_contradiction": 0.43543543543543545,
      "f1_contradiction": 0.516320474777448
    }
  },
  "sentence-bert": {
    "validation": {
      "accuracy": 0.7068730086481566,
      "precision": 0.7079469650979667,
      "recall": 0.7047090716885078,
      "f1": 0.7053487875173469,
      "precision_entailment": 0.6913294797687861,
      "recall_entailment": 0.7410161090458488,
      "f1_entailment": 0.715311004784689,
      "precision_neutral": 0.6636225266362252,
      "recall_neutral": 0.6801872074882995,
      "f1_neutral": 0.6718027734976888,
      "precision_contradiction": 0.7688888888888888,
      "recall_contradiction": 0.6929238985313751,
      "f1_contradiction": 0.7289325842696629
    },
    "test_lay": {
      "accuracy": 0.684234438891413,
      "precision": 0.6848208533775083,
      "recall": 0.6828269802275511,
      "f1": 0.6828554395105749,
      "precision_entailment": 0.6708860759493671,
      "recall_entailment": 0.7215346534653465,
      "f1_entailment": 0.6952892069171139,
      "precision_neutral": 0.656832298136646,
      "recall_neutral": 0.6724960254372019,
      "f1_neutral": 0.6645718774548312,
      "precision_contradiction": 0.7267441860465116,
      "recall_contradiction": 0.6544502617801047,
      "f1_contradiction": 0.6887052341597796
    },
    "test_expert": {
      "accuracy": 0.5425603217158177,
      "precision": 0.5530510381794157,
      "recall": 0.5479843578742128,
      "f1": 0.533345845285821,
      "precision_entailment": 0.5434298440979956,
      "recall_entailment": 0.4687800192122959,
      "f1_entailment": 0.5033522434244456,
      "precision_neutral": 0.5157232704402516,
      "recall_neutral": 0.7817796610169492,
      "f1_neutral": 0.6214736842105263,
      "precision_contradiction": 0.6,
      "recall_contradiction": 0.3933933933933934,
      "f1_contradiction": 0.4752116082224909
    }
  },
  "sentence-bert-epoch-1": {
    "validation": {
      "accuracy": 0.535275375512062,
      "precision": 0.5464256262947814,
      "recall": 0.5292814939039096,
      "f1": 0.5346933875624309,
      "precision_entailment": 0.5049944506104328,
      "recall_entailment": 0.563816604708798,
      "f1_entailment": 0.5327868852459017,
      "precision_neutral": 0.39622641509433965,
      "recall_neutral": 0.42589703588143524,
      "f1_neutral": 0.4105263157894737,
      "precision_contradiction": 0.7380560131795717,
      "recall_contradiction": 0.5981308411214953,
      "f1_contradiction": 0.6607669616519174
    },
    "test_lay": {
      "accuracy": 0.5393003180372558,
      "precision": 0.5492064954364483,
      "recall": 0.5314457672887541,
      "f1": 0.5368917889007072,
      "precision_entailment": 0.5043668122270742,
      "recall_entailment": 0.5717821782178217,
      "f1_entailment": 0.5359628770301624,
      "precision_neutral": 0.39162929745889385,
      "recall_neutral": 0.4165341812400636,
      "f1_neutral": 0.4036979969183359,
      "precision_contradiction": 0.7516233766233766,
      "recall_contradiction": 0.606020942408377,
      "f1_contradiction": 0.6710144927536232
    },
    "test_expert": {
      "accuracy": 0.43532171581769435,
      "precision": 0.46893995334456884,
      "recall": 0.43345085894927965,
      "f1": 0.4275822500436724,
      "precision_entailment": 0.40846994535519127,
      "recall_entailment": 0.574447646493756,
      "f1_entailment": 0.47744510978043914,
      "precision_neutral": 0.3975095785440613,
      "recall_neutral": 0.4396186440677966,
      "f1_neutral": 0.41750503018108653,
      "precision_contradiction": 0.6008403361344538,
      "recall_contradiction": 0.2862862862862863,
      "f1_contradiction": 0.3877966101694915
    }
  },
  "sentence-bert-epoch-2": {
    "validation": {
      "accuracy": 0.646335912608102,
      "precision": 0.6539471610578703,
      "recall": 0.6401931468321248,
      "f1": 0.6430956077557696,
      "precision_entailment": 0.6020618556701031,
      "recall_entailment": 0.7236679058240396,
      "f1_entailment": 0.6572875633089477,
      "precision_neutral": 0.5953565505804311,
      "recall_neutral": 0.5600624024960998,
      "f1_neutral": 0.5771704180064309,
      "precision_contradiction": 0.7644230769230769,
      "recall_contradiction": 0.636849132176235,
      "f1_contradiction": 0.6948288419519301
    },
    "test_lay": {
      "accuracy": 0.651976374375284,
      "precision": 0.6583723326035784,
      "recall": 0.6465107063690829,
      "f1": 0.6488465926124555,
      "precision_entailment": 0.6082901554404145,
      "recall_entailment": 0.7264851485148515,
      "f1_entailment": 0.6621545403271292,
      "precision_neutral": 0.6199324324324325,
      "recall_neutral": 0.5834658187599364,
      "f1_neutral": 0.6011466011466011,
      "precision_contradiction": 0.7468944099378882,
      "recall_contradiction": 0.6295811518324608,
      "f1_contradiction": 0.6832386363636364
    },
    "test_expert": {
      "accuracy": 0.5325067024128687,
      "precision": 0.5509403957768381,
      "recall": 0.534731932717491,
      "f1": 0.5245819170970992,
      "precision_entailment": 0.4905349794238683,
      "recall_entailment": 0.5725264169068204,
      "f1_entailment": 0.5283687943262412,
      "precision_neutral": 0.5290745290745291,
      "recall_neutral": 0.684322033898305,
      "f1_neutral": 0.5967667436489608,
      "precision_contradiction": 0.6332116788321168,
      "recall_contradiction": 0.34734734734734735,
      "f1_contradiction": 0.4486102133160957
    }
  },
  "sentence-bert-epoch-3": {
    "validation": {
      "accuracy": 0.700045516613564,
      "precision": 0.7042376737720906,
      "recall": 0.6959801326060053,
      "f1": 0.697656962893244,
      "precision_entailment": 0.6681034482758621,
      "recall_entailment": 0.7682775712515489,
      "f1_entailment": 0.7146974063400576,
      "precision_neutral": 0.6741935483870968,
      "recall_neutral": 0.6521060842433697,
      "f1_neutral": 0.6629659000793021,
      "precision_contradiction": 0.7704160246533128,
      "recall_contradiction": 0.6675567423230975,
      "f1_contradiction": 0.7153075822603719
    },
    "test_lay": {
      "accuracy": 0.684234438891413,
      "precision": 0.69039671462687,
      "recall": 0.679795539089114,
      "f1": 0.6817729468330285,
      "precision_entailment": 0.6430062630480167,
      "recall_entailment": 0.7623762376237624,
      "f1_entailment": 0.6976217440543602,
      "precision_neutral": 0.6774193548387096,
      "recall_neutral": 0.6343402225755167,
      "f1_neutral": 0.6551724137931034,
      "precision_contradiction": 0.7507645259938838,
      "recall_contradiction": 0.6426701570680629,
      "f1_contradiction": 0.692524682651622
    },
    "test_expert": {
      "accuracy": 0.5348525469168901,
      "precision": 0.5453148471354352,
      "recall": 0.5390402848101199,
      "f1": 0.5267361277609267,
      "precision_entailment": 0.5077220077220077,
      "recall_entailment": 0.505283381364073,
      "f1_entailment": 0.5064997592681753,
      "precision_neutral": 0.5239880059970015,
      "recall_neutral": 0.7404661016949152,
      "f1_neutral": 0.6136962247585601,
      "precision_contradiction": 0.6042345276872965,
      "recall_contradiction": 0.3713713713713714,
      "f1_contradiction": 0.46001239925604465
    }
  },
  "sentence-bert-epoch-4": {
    "validation": {
      "accuracy": 0.7068730086481566,
      "precision": 0.7115416872598552,
      "recall": 0.7023888048333001,
      "f1": 0.7043944762638047,
      "precision_entailment": 0.6709539121114684,
      "recall_entailment": 0.7757125154894672,
      "f1_entailment": 0.7195402298850575,
      "precision_neutral": 0.6802610114192496,
      "recall_neutral": 0.6505460218408736,
      "f1_neutral": 0.6650717703349283,
      "precision_contradiction": 0.783410138248848,
      "recall_contradiction": 0.6809078771695594,
      "f1_contradiction": 0.7285714285714285
    },
    "test_lay": {
      "accuracy": 0.6869604725124944,
      "precision": 0.6904757517369546,
      "recall": 0.6829053067160902,
      "f1": 0.6842862892665931,
      "precision_entailment": 0.6577540106951871,
      "recall_entailment": 0.7611386138613861,
      "f1_entailment": 0.7056798623063684,
      "precision_neutral": 0.6778523489932886,
      "recall_neutral": 0.6422893481717011,
      "f1_neutral": 0.6595918367346939,
      "precision_contradiction": 0.735820895522388,
      "recall_contradiction": 0.6452879581151832,
      "f1_contradiction": 0.6875871687587168
    },
    "test_expert": {
      "accuracy": 0.542225201072386,
      "precision": 0.5519202529921831,
      "recall": 0.5466471453625266,
      "f1": 0.5339059133777176,
      "precision_entailment": 0.5297679112008072,
      "recall_entailment": 0.5043227665706052,
      "f1_entailment": 0.5167322834645669,
      "precision_neutral": 0.5231447465099192,
      "recall_neutral": 0.7542372881355932,
      "f1_neutral": 0.6177874186550976,
      "precision_contradiction": 0.6028481012658228,
      "recall_contradiction": 0.3813813813813814,
      "f1_contradiction": 0.46719803801348864
    }
  },
  "sentence-bert-epoch-5": {
    "validation": {
      "accuracy": 0.7068730086481566,
      "precision": 0.7079469650979667,
      "recall": 0.7047090716885078,
      "f1": 0.7053487875173469,
      "precision_entailment": 0.6913294797687861,
      "recall_entailment": 0.7410161090458488,
      "f1_entailment": 0.715311004784689,
      "precision_neutral": 0.6636225266362252,
      "recall_neutral": 0.6801872074882995,
      "f1_neutral": 0.6718027734976888,
      "precision_contradiction": 0.7688888888888888,
      "recall_contradiction": 0.6929238985313751,
      "f1_contradiction": 0.7289325842696629
    },
    "test_lay": {
      "accuracy": 0.684234438891413,
      "precision": 0.6848208533775083,
      "recall": 0.6828269802275511,
      "f1": 0.6828554395105749,
      "precision_entailment": 0.6708860759493671,
      "recall_entailment": 0.7215346534653465,
      "f1_entailment": 0.6952892069171139,
      "precision_neutral": 0.656832298136646,
      "recall_neutral": 0.6724960254372019,
      "f1_neutral": 0.6645718774548312,
      "precision_contradiction": 0.7267441860465116,
      "recall_contradiction": 0.6544502617801047,
      "f1_contradiction": 0.6887052341597796
    },
    "test_expert": {
      "accuracy": 0.5425603217158177,
      "precision": 0.5530510381794157,
      "recall": 0.5479843578742128,
      "f1": 0.533345845285821,
      "precision_entailment": 0.5434298440979956,
      "recall_entailment": 0.4687800192122959,
      "f1_entailment": 0.5033522434244456,
      "precision_neutral": 0.5157232704402516,
      "recall_neutral": 0.7817796610169492,
      "f1_neutral": 0.6214736842105263,
      "precision_contradiction": 0.6,
      "recall_contradiction": 0.3933933933933934,
      "f1_contradiction": 0.4752116082224909
    }
  },
  "sentence-bert-proper": {
    "validation": {
      "accuracy": 0.70368684569868,
      "precision": 0.7044059996742464,
      "recall": 0.7011229359162571,
      "f1": 0.7017807611385263,
      "precision_entailment": 0.6908045977011494,
      "recall_entailment": 0.7447335811648079,
      "f1_entailment": 0.7167561121049493,
      "precision_neutral": 0.6620583717357911,
      "recall_neutral": 0.672386895475819,
      "f1_neutral": 0.6671826625386997,
      "precision_contradiction": 0.7603550295857988,
      "recall_contradiction": 0.6862483311081442,
      "f1_contradiction": 0.7214035087719298
    },
    "test_lay": {
      "accuracy": 0.6969559291231259,
      "precision": 0.6965522907492881,
      "recall": 0.6951775737383624,
      "f1": 0.6948737239767744,
      "precision_entailment": 0.6939953810623557,
      "recall_entailment": 0.7438118811881188,
      "f1_entailment": 0.7180406212664278,
      "precision_neutral": 0.6620370370370371,
      "recall_neutral": 0.6820349761526232,
      "f1_neutral": 0.6718872357086922,
      "precision_contradiction": 0.7336244541484717,
      "recall_contradiction": 0.6596858638743456,
      "f1_contradiction": 0.6946933149552033
    },
    "test_expert": {
      "accuracy": 0.5472520107238605,
      "precision": 0.5560278818041576,
      "recall": 0.5521471482880005,
      "f1": 0.537566320566898,
      "precision_entailment": 0.5514316012725344,
      "recall_entailment": 0.49951969260326606,
      "f1_entailment": 0.5241935483870968,
      "precision_neutral": 0.5235378031383737,
      "recall_neutral": 0.777542372881356,
      "f1_neutral": 0.6257459505541347,
      "precision_contradiction": 0.593114241001565,
      "recall_contradiction": 0.3793793793793794,
      "f1_contradiction": 0.4627594627594628
    }
  },
  "sentence-bert-proper-epoch-1": {
    "validation": {
      "accuracy": 0.5630405097860719,
      "precision": 0.5745481112110304,
      "recall": 0.546829982946639,
      "f1": 0.5466035194356865,
      "precision_entailment": 0.5090439276485789,
      "recall_entailment": 0.7323420074349443,
      "f1_entailment": 0.600609756097561,
      "precision_neutral": 0.4319148936170213,
      "recall_neutral": 0.3166926677067083,
      "f1_neutral": 0.36543654365436545,
      "precision_contradiction": 0.7826855123674912,
      "recall_contradiction": 0.5914552736982643,
      "f1_contradiction": 0.6737642585551331
    },
    "test_lay": {
      "accuracy": 0.5729213993639255,
      "precision": 0.5803713731441388,
      "recall": 0.5565021225276541,
      "f1": 0.5574134835645971,
      "precision_entailment": 0.5241935483870968,
      "recall_entailment": 0.724009900990099,
      "f1_entailment": 0.6081081081081081,
      "precision_neutral": 0.4346076458752515,
      "recall_neutral": 0.34340222575516693,
      "f1_neutral": 0.3836589698046181,
      "precision_contradiction": 0.782312925170068,
      "recall_contradiction": 0.6020942408376964,
      "f1_contradiction": 0.6804733727810651
    },
    "test_expert": {
      "accuracy": 0.4507372654155496,
      "precision": 0.49148339649930134,
      "recall": 0.44845245060264033,
      "f1": 0.4394125266627265,
      "precision_entailment": 0.4152159896840748,
      "recall_entailment": 0.6186359269932757,
      "f1_entailment": 0.49691358024691357,
      "precision_neutral": 0.4281437125748503,
      "recall_neutral": 0.4544491525423729,
      "f1_neutral": 0.4409044193216855,
      "precision_contradiction": 0.6310904872389791,
      "recall_contradiction": 0.2722722722722723,
      "f1_contradiction": 0.3804195804195804
    }
  },
  "sentence-bert-proper-epoch-2": {
    "validation": {
      "accuracy": 0.6781975421028675,
      "precision": 0.6867021223962692,
      "recall": 0.6785530697619557,
      "f1": 0.6776602549161619,
      "precision_entailment": 0.6761229314420804,
      "recall_entailment": 0.7087980173482032,
      "f1_entailment": 0.6920750151240169,
      "precision_neutral": 0.5921052631578947,
      "recall_neutral": 0.7020280811232449,
      "f1_neutral": 0.6423982869379015,
      "precision_contradiction": 0.7918781725888325,
      "recall_contradiction": 0.6248331108144193,
      "f1_contradiction": 0.6985074626865672
    },
    "test_lay": {
      "accuracy": 0.6701499318491595,
      "precision": 0.6783512418812462,
      "recall": 0.673150736672815,
      "f1": 0.6697243644941664,
      "precision_entailment": 0.6743620899149453,
      "recall_entailment": 0.6868811881188119,
      "f1_entailment": 0.680564071122011,
      "precision_neutral": 0.5851472471190781,
      "recall_neutral": 0.7265500794912559,
      "f1_neutral": 0.64822695035461,
      "precision_contradiction": 0.7755443886097152,
      "recall_contradiction": 0.606020942408377,
      "f1_contradiction": 0.6803820720058781
    },
    "test_expert": {
      "accuracy": 0.5160857908847185,
      "precision": 0.5483300839242308,
      "recall": 0.522661068972064,
      "f1": 0.49834535903620275,
      "precision_entailment": 0.5116022099447514,
      "recall_entailment": 0.4447646493756004,
      "f1_entailment": 0.47584789311408016,
      "precision_neutral": 0.47896039603960394,
      "recall_neutral": 0.8199152542372882,
      "f1_neutral": 0.6046875,
      "precision_contradiction": 0.6544276457883369,
      "recall_contradiction": 0.3033033033033033,
      "f1_contradiction": 0.41450068399452805
    }
  },
  "sentence-bert-proper-epoch-3": {
    "validation": {
      "accuracy": 0.7023213472917615,
      "precision": 0.708463868404935,
      "recall": 0.6987323052033528,
      "f1": 0.6993940864332275,
      "precision_entailment": 0.6773504273504274,
      "recall_entailment": 0.7856257744733581,
      "f1_entailment": 0.7274813539873781,
      "precision_neutral": 0.65402124430956,
      "recall_neutral": 0.672386895475819,
      "f1_neutral": 0.6630769230769231,
      "precision_contradiction": 0.7940199335548173,
      "recall_contradiction": 0.6381842456608812,
      "f1_contradiction": 0.7076239822353811
    },
    "test_lay": {
      "accuracy": 0.6905951840072694,
      "precision": 0.6949069504671322,
      "recall": 0.6890414299256277,
      "f1": 0.6884431230663188,
      "precision_entailment": 0.6681175190424374,
      "recall_entailment": 0.7599009900990099,
      "f1_entailment": 0.7110596409959468,
      "precision_neutral": 0.6545454545454545,
      "recall_neutral": 0.6868044515103339,
      "f1_neutral": 0.6702870442203258,
      "precision_contradiction": 0.7620578778135049,
      "recall_contradiction": 0.6204188481675392,
      "f1_contradiction": 0.683982683982684
    },
    "test_expert": {
      "accuracy": 0.5382037533512064,
      "precision": 0.558592232779437,
      "recall": 0.5435060003017395,
      "f1": 0.52380079311271,
      "precision_entailment": 0.5358606557377049,
      "recall_entailment": 0.5024015369836695,
      "f1_entailment": 0.5185919682697074,
      "precision_neutral": 0.5067114093959731,
      "recall_neutral": 0.7997881355932204,
      "f1_neutral": 0.6203779786359901,
      "precision_contradiction": 0.6332046332046332,
      "recall_contradiction": 0.3283283283283283,
      "f1_contradiction": 0.43243243243243246
    }
  },
  "sentence-bert-proper-epoch-4": {
    "validation": {
      "accuracy": 0.7114246700045517,
      "precision": 0.7170972114618421,
      "recall": 0.709559543268696,
      "f1": 0.7097324110551405,
      "precision_entailment": 0.6891592920353983,
      "recall_entailment": 0.7719950433705081,
      "f1_entailment": 0.72822910578609,
      "precision_neutral": 0.6608187134502924,
      "recall_neutral": 0.7051482059282371,
      "f1_neutral": 0.6822641509433962,
      "precision_contradiction": 0.8013136288998358,
      "recall_contradiction": 0.6515353805073432,
      "f1_contradiction": 0.7187039764359352
    },
    "test_lay": {
      "accuracy": 0.6987732848705134,
      "precision": 0.7015246453805619,
      "recall": 0.6977362127043326,
      "f1": 0.6964634860429824,
      "precision_entailment": 0.6866666666666666,
      "recall_entailment": 0.7648514851485149,
      "f1_entailment": 0.7236533957845434,
      "precision_neutral": 0.6567607726597325,
      "recall_neutral": 0.7027027027027027,
      "f1_neutral": 0.6789554531490015,
      "precision_contradiction": 0.7611464968152867,
      "recall_contradiction": 0.6256544502617801,
      "f1_contradiction": 0.6867816091954023
    },
    "test_expert": {
      "accuracy": 0.546916890080429,
      "precision": 0.5662589257015919,
      "recall": 0.5519061226517388,
      "f1": 0.5331811826708337,
      "precision_entailment": 0.5491388044579534,
      "recall_entailment": 0.5206532180595581,
      "f1_entailment": 0.534516765285996,
      "precision_neutral": 0.5132743362831859,
      "recall_neutral": 0.798728813559322,
      "f1_neutral": 0.6249481972648155,
      "precision_contradiction": 0.6363636363636364,
      "recall_contradiction": 0.33633633633633636,
      "f1_contradiction": 0.4400785854616896
    }
  },
  "sentence-bert-proper-epoch-5": {
    "validation": {
      "accuracy": 0.70368684569868,
      "precision": 0.7044059996742464,
      "recall": 0.7011229359162571,
      "f1": 0.7017807611385263,
      "precision_entailment": 0.6908045977011494,
      "recall_entailment": 0.7447335811648079,
      "f1_entailment": 0.7167561121049493,
      "precision_neutral": 0.6620583717357911,
      "recall_neutral": 0.672386895475819,
      "f1_neutral": 0.6671826625386997,
      "precision_contradiction": 0.7603550295857988,
      "recall_contradiction": 0.6862483311081442,
      "f1_contradiction": 0.7214035087719298
    },
    "test_lay": {
      "accuracy": 0.6969559291231259,
      "precision": 0.6965522907492881,
      "recall": 0.6951775737383624,
      "f1": 0.6948737239767744,
      "precision_entailment": 0.6939953810623557,
      "recall_entailment": 0.7438118811881188,
      "f1_entailment": 0.7180406212664278,
      "precision_neutral": 0.6620370370370371,
      "recall_neutral": 0.6820349761526232,
      "f1_neutral": 0.6718872357086922,
      "precision_contradiction": 0.7336244541484717,
      "recall_contradiction": 0.6596858638743456,
      "f1_contradiction": 0.6946933149552033
    },
    "test_expert": {
      "accuracy": 0.5472520107238605,
      "precision": 0.5560278818041576,
      "recall": 0.5521471482880005,
      "f1": 0.537566320566898,
      "precision_entailment": 0.5514316012725344,
      "recall_entailment": 0.49951969260326606,
      "f1_entailment": 0.5241935483870968,
      "precision_neutral": 0.5235378031383737,
      "recall_neutral": 0.777542372881356,
      "f1_neutral": 0.6257459505541347,
      "precision_contradiction": 0.593114241001565,
      "recall_contradiction": 0.3793793793793794,
      "f1_contradiction": 0.4627594627594628
    }
  },
  "sentence-bert-simple": {
    "validation": {
      "accuracy": 0.7100591715976331,
      "precision": 0.71085677806806,
      "recall": 0.7073545168352496,
      "f1": 0.7081638258504072,
      "precision_entailment": 0.6948571428571428,
      "recall_entailment": 0.7534076827757125,
      "f1_entailment": 0.72294887039239,
      "precision_neutral": 0.6770670826833073,
      "recall_neutral": 0.6770670826833073,
      "f1_neutral": 0.6770670826833073,
      "precision_contradiction": 0.7606461086637298,
      "recall_contradiction": 0.6915887850467289,
      "f1_contradiction": 0.7244755244755244
    },
    "test_lay": {
      "accuracy": 0.692412539754657,
      "precision": 0.6938495671747159,
      "recall": 0.6901604754196026,
      "f1": 0.6906642673152107,
      "precision_entailment": 0.6722972972972973,
      "recall_entailment": 0.7388613861386139,
      "f1_entailment": 0.7040094339622641,
      "precision_neutral": 0.6640378548895899,
      "recall_neutral": 0.6693163751987281,
      "f1_neutral": 0.6666666666666666,
      "precision_contradiction": 0.7452135493372607,
      "recall_contradiction": 0.662303664921466,
      "f1_contradiction": 0.7013167013167013
    },
    "test_expert": {
      "accuracy": 0.5432305630026809,
      "precision": 0.5536482934105803,
      "recall": 0.5482104984305036,
      "f1": 0.5348926082249849,
      "precision_entailment": 0.5421166306695464,
      "recall_entailment": 0.48222862632084534,
      "f1_entailment": 0.5104219623792577,
      "precision_neutral": 0.5163817663817664,
      "recall_neutral": 0.7680084745762712,
      "f1_neutral": 0.6175468483816013,
      "precision_contradiction": 0.6024464831804281,
      "recall_contradiction": 0.3943943943943944,
      "f1_contradiction": 0.4767090139140956
    }
  },
  "sentence-bert-simple-epoch-1": {
    "validation": {
      "accuracy": 0.5065999089667729,
      "precision": 0.5622001249096781,
      "recall": 0.5224285469616299,
      "f1": 0.5043807586097534,
      "precision_entailment": 0.5578406169665809,
      "recall_entailment": 0.26889714993804215,
      "f1_entailment": 0.362876254180602,
      "precision_neutral": 0.3706122448979592,
      "recall_neutral": 0.7082683307332294,
      "f1_neutral": 0.4866023579849946,
      "precision_contradiction": 0.758147512864494,
      "recall_contradiction": 0.5901201602136181,
      "f1_contradiction": 0.6636636636636637
    },
    "test_lay": {
      "accuracy": 0.5084052703316674,
      "precision": 0.5714833770014436,
      "recall": 0.5253901819776031,
      "f1": 0.506305541765982,
      "precision_entailment": 0.5725593667546174,
      "recall_entailment": 0.2685643564356436,
      "f1_entailment": 0.36562763268744736,
      "precision_neutral": 0.3633440514469453,
      "recall_neutral": 0.7186009538950715,
      "f1_neutral": 0.4826481580352376,
      "precision_contradiction": 0.7785467128027682,
      "recall_contradiction": 0.5890052356020943,
      "f1_contradiction": 0.6706408345752608
    },
    "test_expert": {
      "accuracy": 0.43733243967828417,
      "precision": 0.5003719751282155,
      "recall": 0.44667107842794523,
      "f1": 0.4136152852142279,
      "precision_entailment": 0.49429657794676807,
      "recall_entailment": 0.24975984630163303,
      "f1_entailment": 0.3318442884492661,
      "precision_neutral": 0.37881059470264866,
      "recall_neutral": 0.8029661016949152,
      "f1_neutral": 0.5147707979626486,
      "precision_contradiction": 0.6280087527352297,
      "recall_contradiction": 0.2872872872872873,
      "f1_contradiction": 0.3942307692307692
    }
  },
  "sentence-bert-simple-epoch-2": {
    "validation": {
      "accuracy": 0.6609012289485662,
      "precision": 0.6707782036561069,
      "recall": 0.6634558888277512,
      "f1": 0.6615728598824061,
      "precision_entailment": 0.6730523627075351,
      "recall_entailment": 0.6530359355638166,
      "f1_entailment": 0.6628930817610063,
      "precision_neutral": 0.5624227441285538,
      "recall_neutral": 0.7098283931357254,
      "f1_neutral": 0.6275862068965518,
      "precision_contradiction": 0.7768595041322314,
      "recall_contradiction": 0.6275033377837116,
      "f1_contradiction": 0.6942392909896603
    },
    "test_lay": {
      "accuracy": 0.6556110858700591,
      "precision": 0.66430479770204,
      "recall": 0.6576992314760156,
      "f1": 0.6558266614726699,
      "precision_entailment": 0.6563658838071693,
      "recall_entailment": 0.6571782178217822,
      "f1_entailment": 0.6567717996289425,
      "precision_neutral": 0.558408215661104,
      "recall_neutral": 0.6915739268680445,
      "f1_neutral": 0.6178977272727273,
      "precision_contradiction": 0.7781402936378466,
      "recall_contradiction": 0.6243455497382199,
      "f1_contradiction": 0.6928104575163399
    },
    "test_expert": {
      "accuracy": 0.5167560321715817,
      "precision": 0.538197453600714,
      "recall": 0.5217985064469866,
      "f1": 0.5057615512319495,
      "precision_entailment": 0.49796747967479676,
      "recall_entailment": 0.47070124879923153,
      "f1_entailment": 0.4839506172839506,
      "precision_neutral": 0.4883720930232558,
      "recall_neutral": 0.7563559322033898,
      "f1_neutral": 0.5935162094763092,
      "precision_contradiction": 0.6282527881040892,
      "recall_contradiction": 0.3383383383383383,
      "f1_contradiction": 0.4398178269355888
    }
  },
  "sentence-bert-simple-epoch-3": {
    "validation": {
      "accuracy": 0.7032316795630406,
      "precision": 0.7096822797510917,
      "recall": 0.6998253053146133,
      "f1": 0.7008176788047061,
      "precision_entailment": 0.6730769230769231,
      "recall_entailment": 0.7806691449814126,
      "f1_entailment": 0.7228915662650602,
      "precision_neutral": 0.6615620214395099,
      "recall_neutral": 0.6739469578783152,
      "f1_neutral": 0.6676970633693973,
      "precision_contradiction": 0.7944078947368421,
      "recall_contradiction": 0.6448598130841121,
      "f1_contradiction": 0.711864406779661
    },
    "test_lay": {
      "accuracy": 0.6860517946388005,
      "precision": 0.6944120576415442,
      "recall": 0.6832724110523571,
      "f1": 0.6838912031904251,
      "precision_entailment": 0.6477987421383647,
      "recall_entailment": 0.7648514851485149,
      "f1_entailment": 0.7014755959137344,
      "precision_neutral": 0.648062015503876,
      "recall_neutral": 0.6645468998410174,
      "f1_neutral": 0.6562009419152276,
      "precision_contradiction": 0.7873754152823921,
      "recall_contradiction": 0.6204188481675392,
      "f1_contradiction": 0.6939970717423133
    },
    "test_expert": {
      "accuracy": 0.539544235924933,
      "precision": 0.5570840378238539,
      "recall": 0.5439089496944151,
      "f1": 0.5279898116310288,
      "precision_entailment": 0.5180265654648957,
      "recall_entailment": 0.5244956772334294,
      "f1_entailment": 0.5212410501193318,
      "precision_neutral": 0.5193965517241379,
      "recall_neutral": 0.7658898305084746,
      "f1_neutral": 0.6190068493150684,
      "precision_contradiction": 0.6338289962825279,
      "recall_contradiction": 0.34134134134134136,
      "f1_contradiction": 0.44372153545868576
    }
  },
  "sentence-bert-simple-epoch-4": {
    "validation": {
      "accuracy": 0.702776513427401,
      "precision": 0.704096436141813,
      "recall": 0.7000519602680167,
      "f1": 0.7007528258337024,
      "precision_entailment": 0.6873589164785553,
      "recall_entailment": 0.7546468401486989,
      "f1_entailment": 0.7194329592439457,
      "precision_neutral": 0.6708074534161491,
      "recall_neutral": 0.6739469578783152,
      "f1_neutral": 0.6723735408560312,
      "precision_contradiction": 0.7541229385307346,
      "recall_contradiction": 0.671562082777036,
      "f1_contradiction": 0.71045197740113
    },
    "test_lay": {
      "accuracy": 0.6901408450704225,
      "precision": 0.6936332957296149,
      "recall": 0.6880488571584998,
      "f1": 0.6888355617419845,
      "precision_entailment": 0.659316427783903,
      "recall_entailment": 0.7400990099009901,
      "f1_entailment": 0.6973760932944606,
      "precision_neutral": 0.6666666666666666,
      "recall_neutral": 0.670906200317965,
      "f1_neutral": 0.6687797147385103,
      "precision_contradiction": 0.7549167927382754,
      "recall_contradiction": 0.6531413612565445,
      "f1_contradiction": 0.7003508771929825
    },
    "test_expert": {
      "accuracy": 0.5428954423592494,
      "precision": 0.5545304660171171,
      "recall": 0.5477152866000372,
      "f1": 0.533896130293641,
      "precision_entailment": 0.541622760800843,
      "recall_entailment": 0.49375600384245916,
      "f1_entailment": 0.5165829145728643,
      "precision_neutral": 0.5152807391613362,
      "recall_neutral": 0.7680084745762712,
      "f1_neutral": 0.6167588260314759,
      "precision_contradiction": 0.606687898089172,
      "recall_contradiction": 0.3813813813813814,
      "f1_contradiction": 0.4683466502765827
    }
  },
  "sentence-bert-simple-epoch-5": {
    "validation": {
      "accuracy": 0.7100591715976331,
      "precision": 0.71085677806806,
      "recall": 0.7073545168352496,
      "f1": 0.7081638258504072,
      "precision_entailment": 0.6948571428571428,
      "recall_entailment": 0.7534076827757125,
      "f1_entailment": 0.72294887039239,
      "precision_neutral": 0.6770670826833073,
      "recall_neutral": 0.6770670826833073,
      "f1_neutral": 0.6770670826833073,
      "precision_contradiction": 0.7606461086637298,
      "recall_contradiction": 0.6915887850467289,
      "f1_contradiction": 0.7244755244755244
    },
    "test_lay": {
      "accuracy": 0.692412539754657,
      "precision": 0.6938495671747159,
      "recall": 0.6901604754196026,
      "f1": 0.6906642673152107,
      "precision_entailment": 0.6722972972972973,
      "recall_entailment": 0.7388613861386139,
      "f1_entailment": 0.7040094339622641,
      "precision_neutral": 0.6640378548895899,
      "recall_neutral": 0.6693163751987281,
      "f1_neutral": 0.6666666666666666,
      "precision_contradiction": 0.7452135493372607,
      "recall_contradiction": 0.662303664921466,
      "f1_contradiction": 0.7013167013167013
    },
    "test_expert": {
      "accuracy": 0.5432305630026809,
      "precision": 0.5536482934105803,
      "recall": 0.5482104984305036,
      "f1": 0.5348926082249849,
      "precision_entailment": 0.5421166306695464,
      "recall_entailment": 0.48222862632084534,
      "f1_entailment": 0.5104219623792577,
      "precision_neutral": 0.5163817663817664,
      "recall_neutral": 0.7680084745762712,
      "f1_neutral": 0.6175468483816013,
      "precision_contradiction": 0.6024464831804281,
      "recall_contradiction": 0.3943943943943944,
      "f1_contradiction": 0.4767090139140956
    }
  }
}