2025-03-23 22:23:31,191 - INFO - Configuration: {'model': {'name': 'Indo-roBERTa-base', 'pretrained_model_name': 'flax-community/indonesian-roberta-base', 'max_seq_length': 128, 'output_hidden_states': False}, 'training': {'batch_size': 128, 'learning_rate': '2e-5', 'num_epochs': 5, 'warmup_ratio': 0.1, 'weight_decay': 0.01, 'gradient_accumulation_steps': 1, 'seed': 42, 'save_steps': 500, 'eval_steps': 500, 'logging_steps': 100, 'disable_tqdm': False, 'fp16': True}, 'data': {'dataset_name': 'afaji/indonli', 'train_split': 'train', 'validation_split': 'validation', 'test_splits': ['test_lay', 'test_expert'], 'num_workers': 4}, 'output': {'output_dir': '/home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base', 'logging_dir': '/home/jupyter-23522029/indo-NLI-best-model/logs/indo-roberta-base', 'report_dir': '/home/jupyter-23522029/indo-NLI-best-model/reports/indo-roberta-base'}}
2025-03-23 22:23:31,278 - INFO - System information:
2025-03-23 22:23:31,278 - INFO - Python version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]
2025-03-23 22:23:31,278 - INFO - PyTorch version: 2.6.0+cu124
2025-03-23 22:23:31,278 - INFO - CUDA available: Yes
2025-03-23 22:23:31,278 - INFO - CUDA version: 12.4
2025-03-23 22:23:31,318 - INFO - Number of GPUs: 1
2025-03-23 22:23:31,324 - INFO - Current GPU: 0
2025-03-23 22:23:31,324 - INFO - GPU name: NVIDIA RTX A5000
2025-03-23 22:23:31,324 - INFO - Using device: cuda
2025-03-23 22:23:31,325 - INFO - Creating model
2025-03-23 22:23:31,325 - INFO - Creating model of type Indo-roBERTa-base
2025-03-23 22:23:31,325 - INFO - Loading RoBERTa model from flax-community/indonesian-roberta-base
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at flax-community/indonesian-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-03-23 22:23:32,234 - INFO - Loading tokenizer from: flax-community/indonesian-roberta-base
2025-03-23 22:23:32,742 - INFO - Loading datasets
2025-03-23 22:23:32,742 - INFO - Loading IndoNLI dataset (train split)...
2025-03-23 22:23:35,279 - INFO - Loaded 10330 examples from train split
2025-03-23 22:23:35,280 - INFO - Loading IndoNLI dataset (validation split)...
2025-03-23 22:23:36,640 - INFO - Loaded 2197 examples from validation split
2025-03-23 22:23:36,640 - INFO - Creating trainer
2025-03-23 22:23:36,640 - INFO - Using device: cuda
2025-03-23 22:23:36,644 - INFO - Starting training
2025-03-23 22:23:36,644 - INFO - Starting training
/home/jupyter-23522029/indo-NLI-best-model/src/training/trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
2025-03-23 22:23:36,645 - INFO - Epoch 1/5
  0%|                                         | 0/81 [00:00<?, ?it/s]/home/jupyter-23522029/indo-NLI-best-model/src/training/trainer.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Loss: 1.0919:   0%|                           | 0/81 [00:01<?, ?it/s]Loss: 1.0919:   1%|▏                  | 1/81 [00:01<01:48,  1.36s/it]Loss: 1.1259:   1%|▏                  | 1/81 [00:01<01:48,  1.36s/it]Loss: 1.1259:   2%|▍                  | 2/81 [00:01<00:54,  1.46it/s]Loss: 1.0957:   2%|▍                  | 2/81 [00:01<00:54,  1.46it/s]Loss: 1.0957:   4%|▋                  | 3/81 [00:01<00:36,  2.13it/s]Loss: 1.1107:   4%|▋                  | 3/81 [00:01<00:36,  2.13it/s]Loss: 1.1107:   5%|▉                  | 4/81 [00:01<00:28,  2.73it/s]Loss: 1.1394:   5%|▉                  | 4/81 [00:02<00:28,  2.73it/s]Loss: 1.1394:   6%|█▏                 | 5/81 [00:02<00:23,  3.22it/s]Loss: 1.1253:   6%|█▏                 | 5/81 [00:02<00:23,  3.22it/s]Loss: 1.1253:   7%|█▍                 | 6/81 [00:02<00:20,  3.60it/s]Loss: 1.1003:   7%|█▍                 | 6/81 [00:02<00:20,  3.60it/s]Loss: 1.1003:   9%|█▋                 | 7/81 [00:02<00:19,  3.89it/s]Loss: 1.1287:   9%|█▋                 | 7/81 [00:02<00:19,  3.89it/s]Loss: 1.1287:  10%|█▉                 | 8/81 [00:02<00:17,  4.12it/s]Loss: 1.1100:  10%|█▉                 | 8/81 [00:03<00:17,  4.12it/s]Loss: 1.1100:  11%|██                 | 9/81 [00:03<00:16,  4.29it/s]Loss: 1.0998:  11%|██                 | 9/81 [00:03<00:16,  4.29it/s]Loss: 1.0998:  12%|██▏               | 10/81 [00:03<00:16,  4.42it/s]Loss: 1.1064:  12%|██▏               | 10/81 [00:03<00:16,  4.42it/s]Loss: 1.1064:  14%|██▍               | 11/81 [00:03<00:15,  4.52it/s]Loss: 1.0934:  14%|██▍               | 11/81 [00:03<00:15,  4.52it/s]Loss: 1.0934:  15%|██▋               | 12/81 [00:03<00:15,  4.58it/s]Loss: 1.1061:  15%|██▋               | 12/81 [00:03<00:15,  4.58it/s]Loss: 1.1061:  16%|██▉               | 13/81 [00:03<00:14,  4.63it/s]Loss: 1.1307:  16%|██▉               | 13/81 [00:04<00:14,  4.63it/s]Loss: 1.1307:  17%|███               | 14/81 [00:04<00:14,  4.67it/s]Loss: 1.1256:  17%|███               | 14/81 [00:04<00:14,  4.67it/s]Loss: 1.1256:  19%|███▎              | 15/81 [00:04<00:14,  4.69it/s]Loss: 1.1183:  19%|███▎              | 15/81 [00:04<00:14,  4.69it/s]Loss: 1.1183:  20%|███▌              | 16/81 [00:04<00:13,  4.71it/s]Loss: 1.1391:  20%|███▌              | 16/81 [00:04<00:13,  4.71it/s]Loss: 1.1391:  21%|███▊              | 17/81 [00:04<00:13,  4.70it/s]Loss: 1.1296:  21%|███▊              | 17/81 [00:04<00:13,  4.70it/s]Loss: 1.1296:  22%|████              | 18/81 [00:04<00:13,  4.70it/s]Loss: 1.1229:  22%|████              | 18/81 [00:05<00:13,  4.70it/s]Loss: 1.1229:  23%|████▏             | 19/81 [00:05<00:13,  4.71it/s]Loss: 1.1068:  23%|████▏             | 19/81 [00:05<00:13,  4.71it/s]Loss: 1.1068:  25%|████▍             | 20/81 [00:05<00:12,  4.72it/s]Loss: 1.0992:  25%|████▍             | 20/81 [00:05<00:12,  4.72it/s]Loss: 1.0992:  26%|████▋             | 21/81 [00:05<00:12,  4.72it/s]Loss: 1.1279:  26%|████▋             | 21/81 [00:05<00:12,  4.72it/s]Loss: 1.1279:  27%|████▉             | 22/81 [00:05<00:12,  4.72it/s]Loss: 1.0986:  27%|████▉             | 22/81 [00:06<00:12,  4.72it/s]Loss: 1.0986:  28%|█████             | 23/81 [00:06<00:12,  4.72it/s]Loss: 1.0874:  28%|█████             | 23/81 [00:06<00:12,  4.72it/s]Loss: 1.0874:  30%|█████▎            | 24/81 [00:06<00:12,  4.73it/s]Loss: 1.0913:  30%|█████▎            | 24/81 [00:06<00:12,  4.73it/s]Loss: 1.0913:  31%|█████▌            | 25/81 [00:06<00:11,  4.73it/s]Loss: 1.0942:  31%|█████▌            | 25/81 [00:06<00:11,  4.73it/s]Loss: 1.0942:  32%|█████▊            | 26/81 [00:06<00:11,  4.73it/s]Loss: 1.1124:  32%|█████▊            | 26/81 [00:06<00:11,  4.73it/s]Loss: 1.1124:  33%|██████            | 27/81 [00:06<00:11,  4.73it/s]Loss: 1.1099:  33%|██████            | 27/81 [00:07<00:11,  4.73it/s]Loss: 1.1099:  35%|██████▏           | 28/81 [00:07<00:11,  4.73it/s]Loss: 1.1166:  35%|██████▏           | 28/81 [00:07<00:11,  4.73it/s]Loss: 1.1166:  36%|██████▍           | 29/81 [00:07<00:11,  4.72it/s]Loss: 1.1186:  36%|██████▍           | 29/81 [00:07<00:11,  4.72it/s]Loss: 1.1186:  37%|██████▋           | 30/81 [00:07<00:10,  4.72it/s]Loss: 1.0990:  37%|██████▋           | 30/81 [00:07<00:10,  4.72it/s]Loss: 1.0990:  38%|██████▉           | 31/81 [00:07<00:10,  4.74it/s]Loss: 1.0992:  38%|██████▉           | 31/81 [00:07<00:10,  4.74it/s]Loss: 1.0992:  40%|███████           | 32/81 [00:07<00:10,  4.71it/s]Loss: 1.0840:  40%|███████           | 32/81 [00:08<00:10,  4.71it/s]Loss: 1.0840:  41%|███████▎          | 33/81 [00:08<00:10,  4.72it/s]Loss: 1.1285:  41%|███████▎          | 33/81 [00:08<00:10,  4.72it/s]Loss: 1.1285:  42%|███████▌          | 34/81 [00:08<00:09,  4.72it/s]Loss: 1.1205:  42%|███████▌          | 34/81 [00:08<00:09,  4.72it/s]Loss: 1.1205:  43%|███████▊          | 35/81 [00:08<00:09,  4.72it/s]Loss: 1.1005:  43%|███████▊          | 35/81 [00:08<00:09,  4.72it/s]Loss: 1.1005:  44%|████████          | 36/81 [00:08<00:09,  4.69it/s]Loss: 1.0867:  44%|████████          | 36/81 [00:08<00:09,  4.69it/s]Loss: 1.0867:  46%|████████▏         | 37/81 [00:08<00:09,  4.70it/s]Loss: 1.0880:  46%|████████▏         | 37/81 [00:09<00:09,  4.70it/s]Loss: 1.0880:  47%|████████▍         | 38/81 [00:09<00:09,  4.71it/s]Loss: 1.1089:  47%|████████▍         | 38/81 [00:09<00:09,  4.71it/s]Loss: 1.1089:  48%|████████▋         | 39/81 [00:09<00:08,  4.71it/s]Loss: 1.0882:  48%|████████▋         | 39/81 [00:09<00:08,  4.71it/s]Loss: 1.0882:  49%|████████▉         | 40/81 [00:09<00:08,  4.72it/s]Loss: 1.0942:  49%|████████▉         | 40/81 [00:09<00:08,  4.72it/s]Loss: 1.0942:  51%|█████████         | 41/81 [00:09<00:08,  4.73it/s]Loss: 1.1179:  51%|█████████         | 41/81 [00:10<00:08,  4.73it/s]Loss: 1.1179:  52%|█████████▎        | 42/81 [00:10<00:08,  4.73it/s]Loss: 1.0814:  52%|█████████▎        | 42/81 [00:10<00:08,  4.73it/s]Loss: 1.0814:  53%|█████████▌        | 43/81 [00:10<00:08,  4.73it/s]Loss: 1.0922:  53%|█████████▌        | 43/81 [00:10<00:08,  4.73it/s]Loss: 1.0922:  54%|█████████▊        | 44/81 [00:10<00:07,  4.73it/s]Loss: 1.0718:  54%|█████████▊        | 44/81 [00:10<00:07,  4.73it/s]Loss: 1.0718:  56%|██████████        | 45/81 [00:10<00:07,  4.72it/s]Loss: 1.1019:  56%|██████████        | 45/81 [00:10<00:07,  4.72it/s]Loss: 1.1019:  57%|██████████▏       | 46/81 [00:10<00:07,  4.72it/s]Loss: 1.0871:  57%|██████████▏       | 46/81 [00:11<00:07,  4.72it/s]Loss: 1.0871:  58%|██████████▍       | 47/81 [00:11<00:07,  4.72it/s]Loss: 1.0867:  58%|██████████▍       | 47/81 [00:11<00:07,  4.72it/s]Loss: 1.0867:  59%|██████████▋       | 48/81 [00:11<00:06,  4.72it/s]Loss: 1.0448:  59%|██████████▋       | 48/81 [00:11<00:06,  4.72it/s]Loss: 1.0448:  60%|██████████▉       | 49/81 [00:11<00:06,  4.72it/s]Loss: 1.0388:  60%|██████████▉       | 49/81 [00:11<00:06,  4.72it/s]Loss: 1.0388:  62%|███████████       | 50/81 [00:11<00:06,  4.73it/s]Loss: 1.1039:  62%|███████████       | 50/81 [00:11<00:06,  4.73it/s]Loss: 1.1039:  63%|███████████▎      | 51/81 [00:11<00:06,  4.73it/s]Loss: 1.0417:  63%|███████████▎      | 51/81 [00:12<00:06,  4.73it/s]Loss: 1.0417:  64%|███████████▌      | 52/81 [00:12<00:06,  4.71it/s]Loss: 1.0192:  64%|███████████▌      | 52/81 [00:12<00:06,  4.71it/s]Loss: 1.0192:  65%|███████████▊      | 53/81 [00:12<00:05,  4.71it/s]Loss: 1.0451:  65%|███████████▊      | 53/81 [00:12<00:05,  4.71it/s]Loss: 1.0451:  67%|████████████      | 54/81 [00:12<00:05,  4.72it/s]Loss: 1.0300:  67%|████████████      | 54/81 [00:12<00:05,  4.72it/s]Loss: 1.0300:  68%|████████████▏     | 55/81 [00:12<00:05,  4.72it/s]Loss: 1.0359:  68%|████████████▏     | 55/81 [00:13<00:05,  4.72it/s]Loss: 1.0359:  69%|████████████▍     | 56/81 [00:13<00:05,  4.71it/s]Loss: 1.0479:  69%|████████████▍     | 56/81 [00:13<00:05,  4.71it/s]Loss: 1.0479:  70%|████████████▋     | 57/81 [00:13<00:05,  4.71it/s]Loss: 0.9853:  70%|████████████▋     | 57/81 [00:13<00:05,  4.71it/s]Loss: 0.9853:  72%|████████████▉     | 58/81 [00:13<00:04,  4.72it/s]Loss: 0.9656:  72%|████████████▉     | 58/81 [00:13<00:04,  4.72it/s]Loss: 0.9656:  73%|█████████████     | 59/81 [00:13<00:04,  4.73it/s]Loss: 0.9604:  73%|█████████████     | 59/81 [00:13<00:04,  4.73it/s]Loss: 0.9604:  74%|█████████████▎    | 60/81 [00:13<00:04,  4.72it/s]Loss: 0.9347:  74%|█████████████▎    | 60/81 [00:14<00:04,  4.72it/s]Loss: 0.9347:  75%|█████████████▌    | 61/81 [00:14<00:04,  4.72it/s]Loss: 0.9605:  75%|█████████████▌    | 61/81 [00:14<00:04,  4.72it/s]Loss: 0.9605:  77%|█████████████▊    | 62/81 [00:14<00:04,  4.72it/s]Loss: 0.9674:  77%|█████████████▊    | 62/81 [00:14<00:04,  4.72it/s]Loss: 0.9674:  78%|██████████████    | 63/81 [00:14<00:03,  4.73it/s]Loss: 0.9903:  78%|██████████████    | 63/81 [00:14<00:03,  4.73it/s]Loss: 0.9903:  79%|██████████████▏   | 64/81 [00:14<00:03,  4.72it/s]Loss: 0.8698:  79%|██████████████▏   | 64/81 [00:14<00:03,  4.72it/s]Loss: 0.8698:  80%|██████████████▍   | 65/81 [00:14<00:03,  4.72it/s]Loss: 0.9001:  80%|██████████████▍   | 65/81 [00:15<00:03,  4.72it/s]Loss: 0.9001:  81%|██████████████▋   | 66/81 [00:15<00:03,  4.72it/s]Loss: 0.9392:  81%|██████████████▋   | 66/81 [00:15<00:03,  4.72it/s]Loss: 0.9392:  83%|██████████████▉   | 67/81 [00:15<00:02,  4.72it/s]Loss: 0.9059:  83%|██████████████▉   | 67/81 [00:15<00:02,  4.72it/s]Loss: 0.9059:  84%|███████████████   | 68/81 [00:15<00:02,  4.73it/s]Loss: 0.9626:  84%|███████████████   | 68/81 [00:15<00:02,  4.73it/s]Loss: 0.9626:  85%|███████████████▎  | 69/81 [00:15<00:02,  4.71it/s]Loss: 1.0119:  85%|███████████████▎  | 69/81 [00:15<00:02,  4.71it/s]Loss: 1.0119:  86%|███████████████▌  | 70/81 [00:15<00:02,  4.69it/s]Loss: 0.9102:  86%|███████████████▌  | 70/81 [00:16<00:02,  4.69it/s]Loss: 0.9102:  88%|███████████████▊  | 71/81 [00:16<00:02,  4.69it/s]Loss: 0.9021:  88%|███████████████▊  | 71/81 [00:16<00:02,  4.69it/s]Loss: 0.9021:  89%|████████████████  | 72/81 [00:16<00:01,  4.71it/s]Loss: 0.7396:  89%|████████████████  | 72/81 [00:16<00:01,  4.71it/s]Loss: 0.7396:  90%|████████████████▏ | 73/81 [00:16<00:01,  4.71it/s]Loss: 0.8632:  90%|████████████████▏ | 73/81 [00:16<00:01,  4.71it/s]Loss: 0.8632:  91%|████████████████▍ | 74/81 [00:16<00:01,  4.72it/s]Loss: 0.8615:  91%|████████████████▍ | 74/81 [00:17<00:01,  4.72it/s]Loss: 0.8615:  93%|████████████████▋ | 75/81 [00:17<00:01,  4.73it/s]Loss: 0.8358:  93%|████████████████▋ | 75/81 [00:17<00:01,  4.73it/s]Loss: 0.8358:  94%|████████████████▉ | 76/81 [00:17<00:01,  4.74it/s]Loss: 0.9166:  94%|████████████████▉ | 76/81 [00:17<00:01,  4.74it/s]Loss: 0.9166:  95%|█████████████████ | 77/81 [00:17<00:00,  4.71it/s]Loss: 0.8178:  95%|█████████████████ | 77/81 [00:17<00:00,  4.71it/s]Loss: 0.8178:  96%|█████████████████▎| 78/81 [00:17<00:00,  4.72it/s]Loss: 0.9487:  96%|█████████████████▎| 78/81 [00:17<00:00,  4.72it/s]Loss: 0.9487:  98%|█████████████████▌| 79/81 [00:17<00:00,  4.73it/s]Loss: 0.9455:  98%|█████████████████▌| 79/81 [00:18<00:00,  4.73it/s]Loss: 0.9455:  99%|█████████████████▊| 80/81 [00:18<00:00,  4.73it/s]Loss: 0.8083:  99%|█████████████████▊| 80/81 [00:18<00:00,  4.73it/s]Loss: 0.8083: 100%|██████████████████| 81/81 [00:18<00:00,  5.08it/s]Loss: 0.8083: 100%|██████████████████| 81/81 [00:18<00:00,  4.43it/s]
2025-03-23 22:23:54,945 - INFO - Epoch 1 completed. Average loss: 1.0421
2025-03-23 22:23:54,946 - INFO - Running evaluation
Evaluating:   0%|                             | 0/18 [00:00<?, ?it/s]Evaluating:   6%|█▏                   | 1/18 [00:00<00:16,  1.04it/s]Evaluating:  11%|██▎                  | 2/18 [00:01<00:08,  1.88it/s]Evaluating:  17%|███▌                 | 3/18 [00:01<00:05,  2.53it/s]Evaluating:  22%|████▋                | 4/18 [00:01<00:04,  3.02it/s]Evaluating:  28%|█████▊               | 5/18 [00:01<00:03,  3.39it/s]Evaluating:  33%|███████              | 6/18 [00:02<00:03,  3.64it/s]Evaluating:  39%|████████▏            | 7/18 [00:02<00:02,  3.85it/s]Evaluating:  44%|█████████▎           | 8/18 [00:02<00:02,  3.99it/s]Evaluating:  50%|██████████▌          | 9/18 [00:02<00:02,  4.09it/s]Evaluating:  56%|███████████         | 10/18 [00:03<00:01,  4.16it/s]Evaluating:  61%|████████████▏       | 11/18 [00:03<00:01,  4.21it/s]Evaluating:  67%|█████████████▎      | 12/18 [00:03<00:01,  4.24it/s]Evaluating:  72%|██████████████▍     | 13/18 [00:03<00:01,  4.27it/s]Evaluating:  78%|███████████████▌    | 14/18 [00:03<00:00,  4.28it/s]Evaluating:  83%|████████████████▋   | 15/18 [00:04<00:00,  4.29it/s]Evaluating:  89%|█████████████████▊  | 16/18 [00:04<00:00,  4.30it/s]Evaluating:  94%|██████████████████▉ | 17/18 [00:04<00:00,  4.30it/s]Evaluating: 100%|████████████████████| 18/18 [00:04<00:00,  3.76it/s]
2025-03-23 22:23:59,808 - INFO - Eval accuracy: 0.6677287209831588
2025-03-23 22:23:59,808 - INFO - Eval precision: 0.6705520710280481
2025-03-23 22:23:59,809 - INFO - Eval recall: 0.664461082739
2025-03-23 22:23:59,809 - INFO - Eval f1: 0.665999224307336
2025-03-23 22:23:59,809 - INFO - Eval precision_entailment: 0.6395089285714286
2025-03-23 22:23:59,809 - INFO - Eval recall_entailment: 0.7100371747211895
2025-03-23 22:23:59,809 - INFO - Eval f1_entailment: 0.6729301233118027
2025-03-23 22:23:59,809 - INFO - Eval precision_neutral: 0.6244131455399061
2025-03-23 22:23:59,809 - INFO - Eval recall_neutral: 0.6224648985959438
2025-03-23 22:23:59,809 - INFO - Eval f1_neutral: 0.6234375
2025-03-23 22:23:59,809 - INFO - Eval precision_contradiction: 0.7477341389728097
2025-03-23 22:23:59,809 - INFO - Eval recall_contradiction: 0.6608811748998665
2025-03-23 22:23:59,809 - INFO - Eval f1_contradiction: 0.7016300496102055
2025-03-23 22:24:01,042 - INFO - Loading tokenizer from: flax-community/indonesian-roberta-base
2025-03-23 22:24:01,519 - INFO - Tokenizer saved successfully to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/epoch-1
2025-03-23 22:24:01,528 - INFO - Model saved to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/epoch-1
2025-03-23 22:24:01,528 - INFO - Epoch 2/5
  0%|                                         | 0/81 [00:00<?, ?it/s]/home/jupyter-23522029/indo-NLI-best-model/src/training/trainer.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Loss: 0.8712:   0%|                           | 0/81 [00:00<?, ?it/s]Loss: 0.8712:   1%|▏                  | 1/81 [00:00<00:58,  1.36it/s]Loss: 0.7926:   1%|▏                  | 1/81 [00:00<00:58,  1.36it/s]Loss: 0.7926:   2%|▍                  | 2/81 [00:00<00:33,  2.34it/s]Loss: 0.7670:   2%|▍                  | 2/81 [00:01<00:33,  2.34it/s]Loss: 0.7670:   4%|▋                  | 3/81 [00:01<00:25,  3.04it/s]Loss: 0.7855:   4%|▋                  | 3/81 [00:01<00:25,  3.04it/s]Loss: 0.7855:   5%|▉                  | 4/81 [00:01<00:21,  3.54it/s]Loss: 0.9036:   5%|▉                  | 4/81 [00:01<00:21,  3.54it/s]Loss: 0.9036:   6%|█▏                 | 5/81 [00:01<00:19,  3.89it/s]Loss: 0.7995:   6%|█▏                 | 5/81 [00:01<00:19,  3.89it/s]Loss: 0.7995:   7%|█▍                 | 6/81 [00:01<00:18,  4.13it/s]Loss: 0.8001:   7%|█▍                 | 6/81 [00:02<00:18,  4.13it/s]Loss: 0.8001:   9%|█▋                 | 7/81 [00:02<00:17,  4.32it/s]Loss: 0.8015:   9%|█▋                 | 7/81 [00:02<00:17,  4.32it/s]Loss: 0.8015:  10%|█▉                 | 8/81 [00:02<00:16,  4.44it/s]Loss: 0.8367:  10%|█▉                 | 8/81 [00:02<00:16,  4.44it/s]Loss: 0.8367:  11%|██                 | 9/81 [00:02<00:15,  4.53it/s]Loss: 0.7586:  11%|██                 | 9/81 [00:02<00:15,  4.53it/s]Loss: 0.7586:  12%|██▏               | 10/81 [00:02<00:15,  4.59it/s]Loss: 0.8448:  12%|██▏               | 10/81 [00:02<00:15,  4.59it/s]Loss: 0.8448:  14%|██▍               | 11/81 [00:02<00:15,  4.62it/s]Loss: 0.8265:  14%|██▍               | 11/81 [00:03<00:15,  4.62it/s]Loss: 0.8265:  15%|██▋               | 12/81 [00:03<00:14,  4.66it/s]Loss: 0.8604:  15%|██▋               | 12/81 [00:03<00:14,  4.66it/s]Loss: 0.8604:  16%|██▉               | 13/81 [00:03<00:14,  4.65it/s]Loss: 0.8665:  16%|██▉               | 13/81 [00:03<00:14,  4.65it/s]Loss: 0.8665:  17%|███               | 14/81 [00:03<00:14,  4.66it/s]Loss: 0.9438:  17%|███               | 14/81 [00:03<00:14,  4.66it/s]Loss: 0.9438:  19%|███▎              | 15/81 [00:03<00:14,  4.67it/s]Loss: 0.7239:  19%|███▎              | 15/81 [00:03<00:14,  4.67it/s]Loss: 0.7239:  20%|███▌              | 16/81 [00:03<00:13,  4.65it/s]Loss: 0.8659:  20%|███▌              | 16/81 [00:04<00:13,  4.65it/s]Loss: 0.8659:  21%|███▊              | 17/81 [00:04<00:13,  4.66it/s]Loss: 0.8637:  21%|███▊              | 17/81 [00:04<00:13,  4.66it/s]Loss: 0.8637:  22%|████              | 18/81 [00:04<00:13,  4.68it/s]Loss: 0.7200:  22%|████              | 18/81 [00:04<00:13,  4.68it/s]2025-03-23 22:24:06,087 - INFO - Step 100: loss = 0.8227
Loss: 0.7200:  23%|████▏             | 19/81 [00:04<00:13,  4.69it/s]Loss: 0.8237:  23%|████▏             | 19/81 [00:04<00:13,  4.69it/s]Loss: 0.8237:  25%|████▍             | 20/81 [00:04<00:13,  4.69it/s]Loss: 0.6940:  25%|████▍             | 20/81 [00:04<00:13,  4.69it/s]Loss: 0.6940:  26%|████▋             | 21/81 [00:04<00:12,  4.70it/s]Loss: 0.7019:  26%|████▋             | 21/81 [00:05<00:12,  4.70it/s]Loss: 0.7019:  27%|████▉             | 22/81 [00:05<00:12,  4.70it/s]Loss: 0.8589:  27%|████▉             | 22/81 [00:05<00:12,  4.70it/s]Loss: 0.8589:  28%|█████             | 23/81 [00:05<00:12,  4.69it/s]Loss: 0.9673:  28%|█████             | 23/81 [00:05<00:12,  4.69it/s]Loss: 0.9673:  30%|█████▎            | 24/81 [00:05<00:12,  4.70it/s]Loss: 0.7533:  30%|█████▎            | 24/81 [00:05<00:12,  4.70it/s]Loss: 0.7533:  31%|█████▌            | 25/81 [00:05<00:11,  4.71it/s]Loss: 0.8608:  31%|█████▌            | 25/81 [00:06<00:11,  4.71it/s]Loss: 0.8608:  32%|█████▊            | 26/81 [00:06<00:11,  4.71it/s]Loss: 0.8072:  32%|█████▊            | 26/81 [00:06<00:11,  4.71it/s]Loss: 0.8072:  33%|██████            | 27/81 [00:06<00:11,  4.71it/s]Loss: 0.8380:  33%|██████            | 27/81 [00:06<00:11,  4.71it/s]Loss: 0.8380:  35%|██████▏           | 28/81 [00:06<00:11,  4.68it/s]Loss: 0.8405:  35%|██████▏           | 28/81 [00:06<00:11,  4.68it/s]Loss: 0.8405:  36%|██████▍           | 29/81 [00:06<00:11,  4.68it/s]Loss: 0.8434:  36%|██████▍           | 29/81 [00:06<00:11,  4.68it/s]Loss: 0.8434:  37%|██████▋           | 30/81 [00:06<00:10,  4.69it/s]Loss: 0.7820:  37%|██████▋           | 30/81 [00:07<00:10,  4.69it/s]Loss: 0.7820:  38%|██████▉           | 31/81 [00:07<00:10,  4.70it/s]Loss: 0.6931:  38%|██████▉           | 31/81 [00:07<00:10,  4.70it/s]Loss: 0.6931:  40%|███████           | 32/81 [00:07<00:10,  4.70it/s]Loss: 0.7153:  40%|███████           | 32/81 [00:07<00:10,  4.70it/s]Loss: 0.7153:  41%|███████▎          | 33/81 [00:07<00:10,  4.71it/s]Loss: 0.6951:  41%|███████▎          | 33/81 [00:07<00:10,  4.71it/s]Loss: 0.6951:  42%|███████▌          | 34/81 [00:07<00:09,  4.71it/s]Loss: 0.7235:  42%|███████▌          | 34/81 [00:07<00:09,  4.71it/s]Loss: 0.7235:  43%|███████▊          | 35/81 [00:07<00:09,  4.70it/s]Loss: 0.6548:  43%|███████▊          | 35/81 [00:08<00:09,  4.70it/s]Loss: 0.6548:  44%|████████          | 36/81 [00:08<00:09,  4.71it/s]Loss: 0.7301:  44%|████████          | 36/81 [00:08<00:09,  4.71it/s]Loss: 0.7301:  46%|████████▏         | 37/81 [00:08<00:09,  4.68it/s]Loss: 0.7790:  46%|████████▏         | 37/81 [00:08<00:09,  4.68it/s]Loss: 0.7790:  47%|████████▍         | 38/81 [00:08<00:09,  4.69it/s]Loss: 0.8032:  47%|████████▍         | 38/81 [00:08<00:09,  4.69it/s]Loss: 0.8032:  48%|████████▋         | 39/81 [00:08<00:08,  4.69it/s]Loss: 0.7587:  48%|████████▋         | 39/81 [00:09<00:08,  4.69it/s]Loss: 0.7587:  49%|████████▉         | 40/81 [00:09<00:08,  4.69it/s]Loss: 0.8084:  49%|████████▉         | 40/81 [00:09<00:08,  4.69it/s]Loss: 0.8084:  51%|█████████         | 41/81 [00:09<00:08,  4.70it/s]Loss: 0.7286:  51%|█████████         | 41/81 [00:09<00:08,  4.70it/s]Loss: 0.7286:  52%|█████████▎        | 42/81 [00:09<00:08,  4.70it/s]Loss: 0.7827:  52%|█████████▎        | 42/81 [00:09<00:08,  4.70it/s]Loss: 0.7827:  53%|█████████▌        | 43/81 [00:09<00:08,  4.70it/s]Loss: 0.7117:  53%|█████████▌        | 43/81 [00:09<00:08,  4.70it/s]Loss: 0.7117:  54%|█████████▊        | 44/81 [00:09<00:07,  4.70it/s]Loss: 0.7552:  54%|█████████▊        | 44/81 [00:10<00:07,  4.70it/s]Loss: 0.7552:  56%|██████████        | 45/81 [00:10<00:07,  4.70it/s]Loss: 0.6670:  56%|██████████        | 45/81 [00:10<00:07,  4.70it/s]Loss: 0.6670:  57%|██████████▏       | 46/81 [00:10<00:07,  4.70it/s]Loss: 0.6289:  57%|██████████▏       | 46/81 [00:10<00:07,  4.70it/s]Loss: 0.6289:  58%|██████████▍       | 47/81 [00:10<00:07,  4.70it/s]Loss: 0.7615:  58%|██████████▍       | 47/81 [00:10<00:07,  4.70it/s]Loss: 0.7615:  59%|██████████▋       | 48/81 [00:10<00:07,  4.70it/s]Loss: 0.7670:  59%|██████████▋       | 48/81 [00:10<00:07,  4.70it/s]Loss: 0.7670:  60%|██████████▉       | 49/81 [00:10<00:06,  4.71it/s]Loss: 0.7197:  60%|██████████▉       | 49/81 [00:11<00:06,  4.71it/s]Loss: 0.7197:  62%|███████████       | 50/81 [00:11<00:06,  4.71it/s]Loss: 0.7083:  62%|███████████       | 50/81 [00:11<00:06,  4.71it/s]Loss: 0.7083:  63%|███████████▎      | 51/81 [00:11<00:06,  4.71it/s]Loss: 0.7582:  63%|███████████▎      | 51/81 [00:11<00:06,  4.71it/s]Loss: 0.7582:  64%|███████████▌      | 52/81 [00:11<00:06,  4.71it/s]Loss: 0.7540:  64%|███████████▌      | 52/81 [00:11<00:06,  4.71it/s]Loss: 0.7540:  65%|███████████▊      | 53/81 [00:11<00:05,  4.71it/s]Loss: 0.7700:  65%|███████████▊      | 53/81 [00:12<00:05,  4.71it/s]Loss: 0.7700:  67%|████████████      | 54/81 [00:12<00:05,  4.70it/s]Loss: 0.7502:  67%|████████████      | 54/81 [00:12<00:05,  4.70it/s]Loss: 0.7502:  68%|████████████▏     | 55/81 [00:12<00:05,  4.67it/s]Loss: 0.7143:  68%|████████████▏     | 55/81 [00:12<00:05,  4.67it/s]Loss: 0.7143:  69%|████████████▍     | 56/81 [00:12<00:05,  4.68it/s]Loss: 0.6743:  69%|████████████▍     | 56/81 [00:12<00:05,  4.68it/s]Loss: 0.6743:  70%|████████████▋     | 57/81 [00:12<00:05,  4.69it/s]Loss: 0.7511:  70%|████████████▋     | 57/81 [00:12<00:05,  4.69it/s]Loss: 0.7511:  72%|████████████▉     | 58/81 [00:12<00:04,  4.69it/s]Loss: 0.8231:  72%|████████████▉     | 58/81 [00:13<00:04,  4.69it/s]Loss: 0.8231:  73%|█████████████     | 59/81 [00:13<00:04,  4.69it/s]Loss: 0.7066:  73%|█████████████     | 59/81 [00:13<00:04,  4.69it/s]Loss: 0.7066:  74%|█████████████▎    | 60/81 [00:13<00:04,  4.70it/s]Loss: 0.7321:  74%|█████████████▎    | 60/81 [00:13<00:04,  4.70it/s]Loss: 0.7321:  75%|█████████████▌    | 61/81 [00:13<00:04,  4.69it/s]Loss: 0.6252:  75%|█████████████▌    | 61/81 [00:13<00:04,  4.69it/s]Loss: 0.6252:  77%|█████████████▊    | 62/81 [00:13<00:04,  4.70it/s]Loss: 0.6668:  77%|█████████████▊    | 62/81 [00:13<00:04,  4.70it/s]Loss: 0.6668:  78%|██████████████    | 63/81 [00:13<00:03,  4.70it/s]Loss: 0.7579:  78%|██████████████    | 63/81 [00:14<00:03,  4.70it/s]Loss: 0.7579:  79%|██████████████▏   | 64/81 [00:14<00:03,  4.70it/s]Loss: 0.7445:  79%|██████████████▏   | 64/81 [00:14<00:03,  4.70it/s]Loss: 0.7445:  80%|██████████████▍   | 65/81 [00:14<00:03,  4.70it/s]Loss: 0.6812:  80%|██████████████▍   | 65/81 [00:14<00:03,  4.70it/s]Loss: 0.6812:  81%|██████████████▋   | 66/81 [00:14<00:03,  4.69it/s]Loss: 0.7282:  81%|██████████████▋   | 66/81 [00:14<00:03,  4.69it/s]Loss: 0.7282:  83%|██████████████▉   | 67/81 [00:14<00:02,  4.68it/s]Loss: 0.6473:  83%|██████████████▉   | 67/81 [00:14<00:02,  4.68it/s]Loss: 0.6473:  84%|███████████████   | 68/81 [00:14<00:02,  4.68it/s]Loss: 0.6866:  84%|███████████████   | 68/81 [00:15<00:02,  4.68it/s]Loss: 0.6866:  85%|███████████████▎  | 69/81 [00:15<00:02,  4.68it/s]Loss: 0.7665:  85%|███████████████▎  | 69/81 [00:15<00:02,  4.68it/s]Loss: 0.7665:  86%|███████████████▌  | 70/81 [00:15<00:02,  4.69it/s]Loss: 0.7087:  86%|███████████████▌  | 70/81 [00:15<00:02,  4.69it/s]Loss: 0.7087:  88%|███████████████▊  | 71/81 [00:15<00:02,  4.59it/s]Loss: 0.7274:  88%|███████████████▊  | 71/81 [00:15<00:02,  4.59it/s]Loss: 0.7274:  89%|████████████████  | 72/81 [00:15<00:01,  4.62it/s]Loss: 0.8053:  89%|████████████████  | 72/81 [00:16<00:01,  4.62it/s]Loss: 0.8053:  90%|████████████████▏ | 73/81 [00:16<00:01,  4.62it/s]Loss: 0.7020:  90%|████████████████▏ | 73/81 [00:16<00:01,  4.62it/s]Loss: 0.7020:  91%|████████████████▍ | 74/81 [00:16<00:01,  4.63it/s]Loss: 0.7961:  91%|████████████████▍ | 74/81 [00:16<00:01,  4.63it/s]Loss: 0.7961:  93%|████████████████▋ | 75/81 [00:16<00:01,  4.64it/s]Loss: 0.6511:  93%|████████████████▋ | 75/81 [00:16<00:01,  4.64it/s]Loss: 0.6511:  94%|████████████████▉ | 76/81 [00:16<00:01,  4.63it/s]Loss: 0.6480:  94%|████████████████▉ | 76/81 [00:16<00:01,  4.63it/s]Loss: 0.6480:  95%|█████████████████ | 77/81 [00:16<00:00,  4.65it/s]Loss: 0.7331:  95%|█████████████████ | 77/81 [00:17<00:00,  4.65it/s]Loss: 0.7331:  96%|█████████████████▎| 78/81 [00:17<00:00,  4.67it/s]Loss: 0.6378:  96%|█████████████████▎| 78/81 [00:17<00:00,  4.67it/s]Loss: 0.6378:  98%|█████████████████▌| 79/81 [00:17<00:00,  4.68it/s]Loss: 0.8182:  98%|█████████████████▌| 79/81 [00:17<00:00,  4.68it/s]Loss: 0.8182:  99%|█████████████████▊| 80/81 [00:17<00:00,  4.68it/s]Loss: 0.8291:  99%|█████████████████▊| 80/81 [00:17<00:00,  4.68it/s]Loss: 0.8291: 100%|██████████████████| 81/81 [00:17<00:00,  5.04it/s]Loss: 0.8291: 100%|██████████████████| 81/81 [00:17<00:00,  4.55it/s]
2025-03-23 22:24:19,340 - INFO - Epoch 2 completed. Average loss: 0.7628
2025-03-23 22:24:19,341 - INFO - Running evaluation
Evaluating:   0%|                             | 0/18 [00:00<?, ?it/s]Evaluating:   6%|█▏                   | 1/18 [00:00<00:13,  1.29it/s]Evaluating:  11%|██▎                  | 2/18 [00:01<00:07,  2.20it/s]Evaluating:  17%|███▌                 | 3/18 [00:01<00:05,  2.83it/s]Evaluating:  22%|████▋                | 4/18 [00:01<00:04,  3.26it/s]Evaluating:  28%|█████▊               | 5/18 [00:01<00:03,  3.55it/s]Evaluating:  33%|███████              | 6/18 [00:01<00:03,  3.77it/s]Evaluating:  39%|████████▏            | 7/18 [00:02<00:02,  3.93it/s]Evaluating:  44%|█████████▎           | 8/18 [00:02<00:02,  4.03it/s]Evaluating:  50%|██████████▌          | 9/18 [00:02<00:02,  4.10it/s]Evaluating:  56%|███████████         | 10/18 [00:02<00:01,  4.16it/s]Evaluating:  61%|████████████▏       | 11/18 [00:03<00:01,  4.20it/s]Evaluating:  67%|█████████████▎      | 12/18 [00:03<00:01,  4.22it/s]Evaluating:  72%|██████████████▍     | 13/18 [00:03<00:01,  4.23it/s]Evaluating:  78%|███████████████▌    | 14/18 [00:03<00:00,  4.25it/s]Evaluating:  83%|████████████████▋   | 15/18 [00:04<00:00,  4.26it/s]Evaluating:  89%|█████████████████▊  | 16/18 [00:04<00:00,  4.26it/s]Evaluating:  94%|██████████████████▉ | 17/18 [00:04<00:00,  4.27it/s]Evaluating: 100%|████████████████████| 18/18 [00:04<00:00,  3.88it/s]
2025-03-23 22:24:24,075 - INFO - Eval accuracy: 0.7373691397360036
2025-03-23 22:24:24,075 - INFO - Eval precision: 0.7420113760813835
2025-03-23 22:24:24,075 - INFO - Eval recall: 0.7323945985833801
2025-03-23 22:24:24,075 - INFO - Eval f1: 0.7336061312590862
2025-03-23 22:24:24,075 - INFO - Eval precision_entailment: 0.7133689839572193
2025-03-23 22:24:24,075 - INFO - Eval recall_entailment: 0.8265179677819083
2025-03-23 22:24:24,076 - INFO - Eval f1_entailment: 0.7657864523536165
2025-03-23 22:24:24,076 - INFO - Eval precision_neutral: 0.6817472698907956
2025-03-23 22:24:24,076 - INFO - Eval recall_neutral: 0.6817472698907956
2025-03-23 22:24:24,076 - INFO - Eval f1_neutral: 0.6817472698907956
2025-03-23 22:24:24,076 - INFO - Eval precision_contradiction: 0.8309178743961353
2025-03-23 22:24:24,076 - INFO - Eval recall_contradiction: 0.6889185580774366
2025-03-23 22:24:24,076 - INFO - Eval f1_contradiction: 0.7532846715328467
2025-03-23 22:24:25,278 - INFO - Loading tokenizer from: flax-community/indonesian-roberta-base
2025-03-23 22:24:25,755 - INFO - Tokenizer saved successfully to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/epoch-2
2025-03-23 22:24:25,765 - INFO - Model saved to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/epoch-2
2025-03-23 22:24:25,765 - INFO - Epoch 3/5
  0%|                                         | 0/81 [00:00<?, ?it/s]/home/jupyter-23522029/indo-NLI-best-model/src/training/trainer.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Loss: 0.7240:   0%|                           | 0/81 [00:00<?, ?it/s]Loss: 0.7240:   1%|▏                  | 1/81 [00:00<01:09,  1.14it/s]Loss: 0.6745:   1%|▏                  | 1/81 [00:01<01:09,  1.14it/s]Loss: 0.6745:   2%|▍                  | 2/81 [00:01<00:38,  2.06it/s]Loss: 0.6149:   2%|▍                  | 2/81 [00:01<00:38,  2.06it/s]Loss: 0.6149:   4%|▋                  | 3/81 [00:01<00:28,  2.77it/s]Loss: 0.5865:   4%|▋                  | 3/81 [00:01<00:28,  2.77it/s]Loss: 0.5865:   5%|▉                  | 4/81 [00:01<00:23,  3.31it/s]Loss: 0.7543:   5%|▉                  | 4/81 [00:01<00:23,  3.31it/s]Loss: 0.7543:   6%|█▏                 | 5/81 [00:01<00:20,  3.65it/s]Loss: 0.5494:   6%|█▏                 | 5/81 [00:01<00:20,  3.65it/s]Loss: 0.5494:   7%|█▍                 | 6/81 [00:01<00:18,  3.96it/s]Loss: 0.6214:   7%|█▍                 | 6/81 [00:02<00:18,  3.96it/s]Loss: 0.6214:   9%|█▋                 | 7/81 [00:02<00:17,  4.18it/s]Loss: 0.5783:   9%|█▋                 | 7/81 [00:02<00:17,  4.18it/s]Loss: 0.5783:  10%|█▉                 | 8/81 [00:02<00:16,  4.34it/s]Loss: 0.6110:  10%|█▉                 | 8/81 [00:02<00:16,  4.34it/s]Loss: 0.6110:  11%|██                 | 9/81 [00:02<00:16,  4.45it/s]Loss: 0.6721:  11%|██                 | 9/81 [00:02<00:16,  4.45it/s]Loss: 0.6721:  12%|██▏               | 10/81 [00:02<00:15,  4.52it/s]Loss: 0.6824:  12%|██▏               | 10/81 [00:03<00:15,  4.52it/s]Loss: 0.6824:  14%|██▍               | 11/81 [00:03<00:15,  4.58it/s]Loss: 0.6273:  14%|██▍               | 11/81 [00:03<00:15,  4.58it/s]Loss: 0.6273:  15%|██▋               | 12/81 [00:03<00:14,  4.62it/s]Loss: 0.6634:  15%|██▋               | 12/81 [00:03<00:14,  4.62it/s]Loss: 0.6634:  16%|██▉               | 13/81 [00:03<00:14,  4.64it/s]Loss: 0.7044:  16%|██▉               | 13/81 [00:03<00:14,  4.64it/s]Loss: 0.7044:  17%|███               | 14/81 [00:03<00:14,  4.65it/s]Loss: 0.6049:  17%|███               | 14/81 [00:03<00:14,  4.65it/s]Loss: 0.6049:  19%|███▎              | 15/81 [00:03<00:14,  4.66it/s]Loss: 0.5118:  19%|███▎              | 15/81 [00:04<00:14,  4.66it/s]Loss: 0.5118:  20%|███▌              | 16/81 [00:04<00:13,  4.66it/s]Loss: 0.6092:  20%|███▌              | 16/81 [00:04<00:13,  4.66it/s]Loss: 0.6092:  21%|███▊              | 17/81 [00:04<00:13,  4.67it/s]Loss: 0.6884:  21%|███▊              | 17/81 [00:04<00:13,  4.67it/s]Loss: 0.6884:  22%|████              | 18/81 [00:04<00:13,  4.67it/s]Loss: 0.7084:  22%|████              | 18/81 [00:04<00:13,  4.67it/s]Loss: 0.7084:  23%|████▏             | 19/81 [00:04<00:13,  4.68it/s]Loss: 0.6527:  23%|████▏             | 19/81 [00:04<00:13,  4.68it/s]Loss: 0.6527:  25%|████▍             | 20/81 [00:04<00:13,  4.69it/s]Loss: 0.5912:  25%|████▍             | 20/81 [00:05<00:13,  4.69it/s]Loss: 0.5912:  26%|████▋             | 21/81 [00:05<00:12,  4.69it/s]Loss: 0.6497:  26%|████▋             | 21/81 [00:05<00:12,  4.69it/s]Loss: 0.6497:  27%|████▉             | 22/81 [00:05<00:12,  4.69it/s]Loss: 0.6248:  27%|████▉             | 22/81 [00:05<00:12,  4.69it/s]Loss: 0.6248:  28%|█████             | 23/81 [00:05<00:12,  4.69it/s]Loss: 0.6875:  28%|█████             | 23/81 [00:05<00:12,  4.69it/s]Loss: 0.6875:  30%|█████▎            | 24/81 [00:05<00:12,  4.69it/s]Loss: 0.5640:  30%|█████▎            | 24/81 [00:05<00:12,  4.69it/s]Loss: 0.5640:  31%|█████▌            | 25/81 [00:05<00:11,  4.69it/s]Loss: 0.5324:  31%|█████▌            | 25/81 [00:06<00:11,  4.69it/s]Loss: 0.5324:  32%|█████▊            | 26/81 [00:06<00:11,  4.69it/s]Loss: 0.6234:  32%|█████▊            | 26/81 [00:06<00:11,  4.69it/s]Loss: 0.6234:  33%|██████            | 27/81 [00:06<00:11,  4.69it/s]Loss: 0.5792:  33%|██████            | 27/81 [00:06<00:11,  4.69it/s]Loss: 0.5792:  35%|██████▏           | 28/81 [00:06<00:11,  4.66it/s]Loss: 0.6377:  35%|██████▏           | 28/81 [00:06<00:11,  4.66it/s]Loss: 0.6377:  36%|██████▍           | 29/81 [00:06<00:11,  4.66it/s]Loss: 0.8213:  36%|██████▍           | 29/81 [00:07<00:11,  4.66it/s]Loss: 0.8213:  37%|██████▋           | 30/81 [00:07<00:10,  4.67it/s]Loss: 0.6158:  37%|██████▋           | 30/81 [00:07<00:10,  4.67it/s]Loss: 0.6158:  38%|██████▉           | 31/81 [00:07<00:10,  4.65it/s]Loss: 0.5650:  38%|██████▉           | 31/81 [00:07<00:10,  4.65it/s]Loss: 0.5650:  40%|███████           | 32/81 [00:07<00:10,  4.66it/s]Loss: 0.7107:  40%|███████           | 32/81 [00:07<00:10,  4.66it/s]Loss: 0.7107:  41%|███████▎          | 33/81 [00:07<00:10,  4.67it/s]Loss: 0.6125:  41%|███████▎          | 33/81 [00:07<00:10,  4.67it/s]Loss: 0.6125:  42%|███████▌          | 34/81 [00:07<00:10,  4.67it/s]Loss: 0.6716:  42%|███████▌          | 34/81 [00:08<00:10,  4.67it/s]Loss: 0.6716:  43%|███████▊          | 35/81 [00:08<00:09,  4.68it/s]Loss: 0.6080:  43%|███████▊          | 35/81 [00:08<00:09,  4.68it/s]Loss: 0.6080:  44%|████████          | 36/81 [00:08<00:09,  4.66it/s]Loss: 0.5662:  44%|████████          | 36/81 [00:08<00:09,  4.66it/s]Loss: 0.5662:  46%|████████▏         | 37/81 [00:08<00:09,  4.67it/s]Loss: 0.6593:  46%|████████▏         | 37/81 [00:08<00:09,  4.67it/s]2025-03-23 22:24:34,545 - INFO - Step 200: loss = 0.6358
Loss: 0.6593:  47%|████████▍         | 38/81 [00:08<00:09,  4.67it/s]Loss: 0.5444:  47%|████████▍         | 38/81 [00:08<00:09,  4.67it/s]Loss: 0.5444:  48%|████████▋         | 39/81 [00:08<00:08,  4.67it/s]Loss: 0.5176:  48%|████████▋         | 39/81 [00:09<00:08,  4.67it/s]Loss: 0.5176:  49%|████████▉         | 40/81 [00:09<00:08,  4.68it/s]Loss: 0.6452:  49%|████████▉         | 40/81 [00:09<00:08,  4.68it/s]Loss: 0.6452:  51%|█████████         | 41/81 [00:09<00:08,  4.68it/s]Loss: 0.5161:  51%|█████████         | 41/81 [00:09<00:08,  4.68it/s]Loss: 0.5161:  52%|█████████▎        | 42/81 [00:09<00:08,  4.66it/s]Loss: 0.5920:  52%|█████████▎        | 42/81 [00:09<00:08,  4.66it/s]Loss: 0.5920:  53%|█████████▌        | 43/81 [00:09<00:08,  4.66it/s]Loss: 0.5589:  53%|█████████▌        | 43/81 [00:10<00:08,  4.66it/s]Loss: 0.5589:  54%|█████████▊        | 44/81 [00:10<00:07,  4.66it/s]Loss: 0.6317:  54%|█████████▊        | 44/81 [00:10<00:07,  4.66it/s]Loss: 0.6317:  56%|██████████        | 45/81 [00:10<00:07,  4.67it/s]Loss: 0.4173:  56%|██████████        | 45/81 [00:10<00:07,  4.67it/s]Loss: 0.4173:  57%|██████████▏       | 46/81 [00:10<00:07,  4.66it/s]Loss: 0.5184:  57%|██████████▏       | 46/81 [00:10<00:07,  4.66it/s]Loss: 0.5184:  58%|██████████▍       | 47/81 [00:10<00:07,  4.67it/s]Loss: 0.5793:  58%|██████████▍       | 47/81 [00:10<00:07,  4.67it/s]Loss: 0.5793:  59%|██████████▋       | 48/81 [00:10<00:07,  4.67it/s]Loss: 0.6619:  59%|██████████▋       | 48/81 [00:11<00:07,  4.67it/s]Loss: 0.6619:  60%|██████████▉       | 49/81 [00:11<00:06,  4.67it/s]Loss: 0.6488:  60%|██████████▉       | 49/81 [00:11<00:06,  4.67it/s]Loss: 0.6488:  62%|███████████       | 50/81 [00:11<00:06,  4.66it/s]Loss: 0.5517:  62%|███████████       | 50/81 [00:11<00:06,  4.66it/s]Loss: 0.5517:  63%|███████████▎      | 51/81 [00:11<00:06,  4.65it/s]Loss: 0.6122:  63%|███████████▎      | 51/81 [00:11<00:06,  4.65it/s]Loss: 0.6122:  64%|███████████▌      | 52/81 [00:11<00:06,  4.66it/s]Loss: 0.7214:  64%|███████████▌      | 52/81 [00:11<00:06,  4.66it/s]Loss: 0.7214:  65%|███████████▊      | 53/81 [00:11<00:05,  4.67it/s]Loss: 0.6351:  65%|███████████▊      | 53/81 [00:12<00:05,  4.67it/s]Loss: 0.6351:  67%|████████████      | 54/81 [00:12<00:05,  4.67it/s]Loss: 0.6989:  67%|████████████      | 54/81 [00:12<00:05,  4.67it/s]Loss: 0.6989:  68%|████████████▏     | 55/81 [00:12<00:05,  4.68it/s]Loss: 0.5408:  68%|████████████▏     | 55/81 [00:12<00:05,  4.68it/s]Loss: 0.5408:  69%|████████████▍     | 56/81 [00:12<00:05,  4.67it/s]Loss: 0.6483:  69%|████████████▍     | 56/81 [00:12<00:05,  4.67it/s]Loss: 0.6483:  70%|████████████▋     | 57/81 [00:12<00:05,  4.67it/s]Loss: 0.6463:  70%|████████████▋     | 57/81 [00:13<00:05,  4.67it/s]Loss: 0.6463:  72%|████████████▉     | 58/81 [00:13<00:04,  4.67it/s]Loss: 0.5928:  72%|████████████▉     | 58/81 [00:13<00:04,  4.67it/s]Loss: 0.5928:  73%|█████████████     | 59/81 [00:13<00:04,  4.67it/s]Loss: 0.6309:  73%|█████████████     | 59/81 [00:13<00:04,  4.67it/s]Loss: 0.6309:  74%|█████████████▎    | 60/81 [00:13<00:04,  4.67it/s]Loss: 0.5294:  74%|█████████████▎    | 60/81 [00:13<00:04,  4.67it/s]Loss: 0.5294:  75%|█████████████▌    | 61/81 [00:13<00:04,  4.68it/s]Loss: 0.5797:  75%|█████████████▌    | 61/81 [00:13<00:04,  4.68it/s]Loss: 0.5797:  77%|█████████████▊    | 62/81 [00:13<00:04,  4.68it/s]Loss: 0.6999:  77%|█████████████▊    | 62/81 [00:14<00:04,  4.68it/s]Loss: 0.6999:  78%|██████████████    | 63/81 [00:14<00:03,  4.68it/s]Loss: 0.6748:  78%|██████████████    | 63/81 [00:14<00:03,  4.68it/s]Loss: 0.6748:  79%|██████████████▏   | 64/81 [00:14<00:03,  4.67it/s]Loss: 0.6085:  79%|██████████████▏   | 64/81 [00:14<00:03,  4.67it/s]Loss: 0.6085:  80%|██████████████▍   | 65/81 [00:14<00:03,  4.67it/s]Loss: 0.5160:  80%|██████████████▍   | 65/81 [00:14<00:03,  4.67it/s]Loss: 0.5160:  81%|██████████████▋   | 66/81 [00:14<00:03,  4.67it/s]Loss: 0.6403:  81%|██████████████▋   | 66/81 [00:14<00:03,  4.67it/s]Loss: 0.6403:  83%|██████████████▉   | 67/81 [00:14<00:03,  4.66it/s]Loss: 0.5806:  83%|██████████████▉   | 67/81 [00:15<00:03,  4.66it/s]Loss: 0.5806:  84%|███████████████   | 68/81 [00:15<00:02,  4.67it/s]Loss: 0.6630:  84%|███████████████   | 68/81 [00:15<00:02,  4.67it/s]Loss: 0.6630:  85%|███████████████▎  | 69/81 [00:15<00:02,  4.67it/s]Loss: 0.5415:  85%|███████████████▎  | 69/81 [00:15<00:02,  4.67it/s]Loss: 0.5415:  86%|███████████████▌  | 70/81 [00:15<00:02,  4.67it/s]Loss: 0.7520:  86%|███████████████▌  | 70/81 [00:15<00:02,  4.67it/s]Loss: 0.7520:  88%|███████████████▊  | 71/81 [00:15<00:02,  4.66it/s]Loss: 0.6247:  88%|███████████████▊  | 71/81 [00:16<00:02,  4.66it/s]Loss: 0.6247:  89%|████████████████  | 72/81 [00:16<00:01,  4.65it/s]Loss: 0.7601:  89%|████████████████  | 72/81 [00:16<00:01,  4.65it/s]Loss: 0.7601:  90%|████████████████▏ | 73/81 [00:16<00:01,  4.63it/s]Loss: 0.6138:  90%|████████████████▏ | 73/81 [00:16<00:01,  4.63it/s]Loss: 0.6138:  91%|████████████████▍ | 74/81 [00:16<00:01,  4.64it/s]Loss: 0.7382:  91%|████████████████▍ | 74/81 [00:16<00:01,  4.64it/s]Loss: 0.7382:  93%|████████████████▋ | 75/81 [00:16<00:01,  4.66it/s]Loss: 0.7249:  93%|████████████████▋ | 75/81 [00:16<00:01,  4.66it/s]Loss: 0.7249:  94%|████████████████▉ | 76/81 [00:16<00:01,  4.65it/s]Loss: 0.6866:  94%|████████████████▉ | 76/81 [00:17<00:01,  4.65it/s]Loss: 0.6866:  95%|█████████████████ | 77/81 [00:17<00:00,  4.66it/s]Loss: 0.6056:  95%|█████████████████ | 77/81 [00:17<00:00,  4.66it/s]Loss: 0.6056:  96%|█████████████████▎| 78/81 [00:17<00:00,  4.66it/s]Loss: 0.6144:  96%|█████████████████▎| 78/81 [00:17<00:00,  4.66it/s]Loss: 0.6144:  98%|█████████████████▌| 79/81 [00:17<00:00,  4.66it/s]Loss: 0.6727:  98%|█████████████████▌| 79/81 [00:17<00:00,  4.66it/s]Loss: 0.6727:  99%|█████████████████▊| 80/81 [00:17<00:00,  4.66it/s]Loss: 0.6106:  99%|█████████████████▊| 80/81 [00:17<00:00,  4.66it/s]Loss: 0.6106: 100%|██████████████████| 81/81 [00:17<00:00,  5.03it/s]Loss: 0.6106: 100%|██████████████████| 81/81 [00:18<00:00,  4.49it/s]
2025-03-23 22:24:43,813 - INFO - Epoch 3 completed. Average loss: 0.6260
2025-03-23 22:24:43,814 - INFO - Running evaluation
Evaluating:   0%|                             | 0/18 [00:00<?, ?it/s]Evaluating:   6%|█▏                   | 1/18 [00:00<00:13,  1.26it/s]Evaluating:  11%|██▎                  | 2/18 [00:01<00:07,  2.15it/s]Evaluating:  17%|███▌                 | 3/18 [00:01<00:05,  2.79it/s]Evaluating:  22%|████▋                | 4/18 [00:01<00:04,  3.22it/s]Evaluating:  28%|█████▊               | 5/18 [00:01<00:03,  3.50it/s]Evaluating:  33%|███████              | 6/18 [00:01<00:03,  3.73it/s]Evaluating:  39%|████████▏            | 7/18 [00:02<00:02,  3.90it/s]Evaluating:  44%|█████████▎           | 8/18 [00:02<00:02,  4.00it/s]Evaluating:  50%|██████████▌          | 9/18 [00:02<00:02,  4.07it/s]Evaluating:  56%|███████████         | 10/18 [00:02<00:01,  4.12it/s]Evaluating:  61%|████████████▏       | 11/18 [00:03<00:01,  4.16it/s]Evaluating:  67%|█████████████▎      | 12/18 [00:03<00:01,  4.18it/s]Evaluating:  72%|██████████████▍     | 13/18 [00:03<00:01,  4.19it/s]Evaluating:  78%|███████████████▌    | 14/18 [00:03<00:00,  4.20it/s]Evaluating:  83%|████████████████▋   | 15/18 [00:04<00:00,  4.21it/s]Evaluating:  89%|█████████████████▊  | 16/18 [00:04<00:00,  4.22it/s]Evaluating:  94%|██████████████████▉ | 17/18 [00:04<00:00,  4.22it/s]Evaluating: 100%|████████████████████| 18/18 [00:04<00:00,  3.84it/s]
2025-03-23 22:24:48,602 - INFO - Eval accuracy: 0.7537551206190259
2025-03-23 22:24:48,602 - INFO - Eval precision: 0.7556471192902223
2025-03-23 22:24:48,603 - INFO - Eval recall: 0.7544381729872027
2025-03-23 22:24:48,603 - INFO - Eval f1: 0.7527418865768679
2025-03-23 22:24:48,603 - INFO - Eval precision_entailment: 0.7891332470892626
2025-03-23 22:24:48,603 - INFO - Eval recall_entailment: 0.7558859975216853
2025-03-23 22:24:48,603 - INFO - Eval f1_entailment: 0.7721518987341772
2025-03-23 22:24:48,603 - INFO - Eval precision_neutral: 0.6573333333333333
2025-03-23 22:24:48,603 - INFO - Eval recall_neutral: 0.7691107644305772
2025-03-23 22:24:48,603 - INFO - Eval f1_neutral: 0.7088425593098491
2025-03-23 22:24:48,603 - INFO - Eval precision_contradiction: 0.8204747774480712
2025-03-23 22:24:48,603 - INFO - Eval recall_contradiction: 0.7383177570093458
2025-03-23 22:24:48,603 - INFO - Eval f1_contradiction: 0.7772312016865777
2025-03-23 22:24:49,866 - INFO - Loading tokenizer from: flax-community/indonesian-roberta-base
2025-03-23 22:24:50,355 - INFO - Tokenizer saved successfully to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/epoch-3
2025-03-23 22:24:50,363 - INFO - Model saved to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/epoch-3
2025-03-23 22:24:50,364 - INFO - Epoch 4/5
  0%|                                         | 0/81 [00:00<?, ?it/s]/home/jupyter-23522029/indo-NLI-best-model/src/training/trainer.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Loss: 0.6403:   0%|                           | 0/81 [00:00<?, ?it/s]Loss: 0.6403:   1%|▏                  | 1/81 [00:00<01:04,  1.25it/s]Loss: 0.5217:   1%|▏                  | 1/81 [00:01<01:04,  1.25it/s]Loss: 0.5217:   2%|▍                  | 2/81 [00:01<00:35,  2.20it/s]Loss: 0.5113:   2%|▍                  | 2/81 [00:01<00:35,  2.20it/s]Loss: 0.5113:   4%|▋                  | 3/81 [00:01<00:26,  2.90it/s]Loss: 0.5579:   4%|▋                  | 3/81 [00:01<00:26,  2.90it/s]Loss: 0.5579:   5%|▉                  | 4/81 [00:01<00:22,  3.40it/s]Loss: 0.5825:   5%|▉                  | 4/81 [00:01<00:22,  3.40it/s]Loss: 0.5825:   6%|█▏                 | 5/81 [00:01<00:20,  3.75it/s]Loss: 0.5299:   6%|█▏                 | 5/81 [00:01<00:20,  3.75it/s]Loss: 0.5299:   7%|█▍                 | 6/81 [00:01<00:18,  4.02it/s]Loss: 0.4534:   7%|█▍                 | 6/81 [00:02<00:18,  4.02it/s]Loss: 0.4534:   9%|█▋                 | 7/81 [00:02<00:17,  4.22it/s]Loss: 0.6219:   9%|█▋                 | 7/81 [00:02<00:17,  4.22it/s]Loss: 0.6219:  10%|█▉                 | 8/81 [00:02<00:16,  4.34it/s]Loss: 0.5374:  10%|█▉                 | 8/81 [00:02<00:16,  4.34it/s]Loss: 0.5374:  11%|██                 | 9/81 [00:02<00:16,  4.44it/s]Loss: 0.5317:  11%|██                 | 9/81 [00:02<00:16,  4.44it/s]Loss: 0.5317:  12%|██▏               | 10/81 [00:02<00:15,  4.50it/s]Loss: 0.6187:  12%|██▏               | 10/81 [00:02<00:15,  4.50it/s]Loss: 0.6187:  14%|██▍               | 11/81 [00:02<00:15,  4.54it/s]Loss: 0.5343:  14%|██▍               | 11/81 [00:03<00:15,  4.54it/s]Loss: 0.5343:  15%|██▋               | 12/81 [00:03<00:15,  4.57it/s]Loss: 0.5747:  15%|██▋               | 12/81 [00:03<00:15,  4.57it/s]Loss: 0.5747:  16%|██▉               | 13/81 [00:03<00:14,  4.59it/s]Loss: 0.5653:  16%|██▉               | 13/81 [00:03<00:14,  4.59it/s]Loss: 0.5653:  17%|███               | 14/81 [00:03<00:14,  4.62it/s]Loss: 0.6046:  17%|███               | 14/81 [00:03<00:14,  4.62it/s]Loss: 0.6046:  19%|███▎              | 15/81 [00:03<00:14,  4.63it/s]Loss: 0.5638:  19%|███▎              | 15/81 [00:04<00:14,  4.63it/s]Loss: 0.5638:  20%|███▌              | 16/81 [00:04<00:14,  4.64it/s]Loss: 0.5665:  20%|███▌              | 16/81 [00:04<00:14,  4.64it/s]Loss: 0.5665:  21%|███▊              | 17/81 [00:04<00:13,  4.63it/s]Loss: 0.5477:  21%|███▊              | 17/81 [00:04<00:13,  4.63it/s]Loss: 0.5477:  22%|████              | 18/81 [00:04<00:13,  4.63it/s]Loss: 0.5997:  22%|████              | 18/81 [00:04<00:13,  4.63it/s]Loss: 0.5997:  23%|████▏             | 19/81 [00:04<00:13,  4.64it/s]Loss: 0.4674:  23%|████▏             | 19/81 [00:04<00:13,  4.64it/s]Loss: 0.4674:  25%|████▍             | 20/81 [00:04<00:13,  4.64it/s]Loss: 0.5026:  25%|████▍             | 20/81 [00:05<00:13,  4.64it/s]Loss: 0.5026:  26%|████▋             | 21/81 [00:05<00:12,  4.64it/s]Loss: 0.4856:  26%|████▋             | 21/81 [00:05<00:12,  4.64it/s]Loss: 0.4856:  27%|████▉             | 22/81 [00:05<00:12,  4.65it/s]Loss: 0.5128:  27%|████▉             | 22/81 [00:05<00:12,  4.65it/s]Loss: 0.5128:  28%|█████             | 23/81 [00:05<00:12,  4.65it/s]Loss: 0.5283:  28%|█████             | 23/81 [00:05<00:12,  4.65it/s]Loss: 0.5283:  30%|█████▎            | 24/81 [00:05<00:12,  4.60it/s]Loss: 0.5183:  30%|█████▎            | 24/81 [00:05<00:12,  4.60it/s]Loss: 0.5183:  31%|█████▌            | 25/81 [00:05<00:12,  4.59it/s]Loss: 0.4684:  31%|█████▌            | 25/81 [00:06<00:12,  4.59it/s]Loss: 0.4684:  32%|█████▊            | 26/81 [00:06<00:11,  4.61it/s]Loss: 0.5298:  32%|█████▊            | 26/81 [00:06<00:11,  4.61it/s]Loss: 0.5298:  33%|██████            | 27/81 [00:06<00:11,  4.60it/s]Loss: 0.6928:  33%|██████            | 27/81 [00:06<00:11,  4.60it/s]Loss: 0.6928:  35%|██████▏           | 28/81 [00:06<00:11,  4.59it/s]Loss: 0.6496:  35%|██████▏           | 28/81 [00:06<00:11,  4.59it/s]Loss: 0.6496:  36%|██████▍           | 29/81 [00:06<00:11,  4.68it/s]Loss: 0.5275:  36%|██████▍           | 29/81 [00:07<00:11,  4.68it/s]Loss: 0.5275:  37%|██████▋           | 30/81 [00:07<00:10,  4.67it/s]Loss: 0.5095:  37%|██████▋           | 30/81 [00:07<00:10,  4.67it/s]Loss: 0.5095:  38%|██████▉           | 31/81 [00:07<00:10,  4.66it/s]Loss: 0.4236:  38%|██████▉           | 31/81 [00:07<00:10,  4.66it/s]Loss: 0.4236:  40%|███████           | 32/81 [00:07<00:10,  4.66it/s]Loss: 0.5025:  40%|███████           | 32/81 [00:07<00:10,  4.66it/s]Loss: 0.5025:  41%|███████▎          | 33/81 [00:07<00:10,  4.66it/s]Loss: 0.5902:  41%|███████▎          | 33/81 [00:07<00:10,  4.66it/s]Loss: 0.5902:  42%|███████▌          | 34/81 [00:07<00:10,  4.66it/s]Loss: 0.4631:  42%|███████▌          | 34/81 [00:08<00:10,  4.66it/s]Loss: 0.4631:  43%|███████▊          | 35/81 [00:08<00:09,  4.66it/s]Loss: 0.5178:  43%|███████▊          | 35/81 [00:08<00:09,  4.66it/s]Loss: 0.5178:  44%|████████          | 36/81 [00:08<00:09,  4.65it/s]Loss: 0.5160:  44%|████████          | 36/81 [00:08<00:09,  4.65it/s]Loss: 0.5160:  46%|████████▏         | 37/81 [00:08<00:09,  4.64it/s]Loss: 0.4884:  46%|████████▏         | 37/81 [00:08<00:09,  4.64it/s]Loss: 0.4884:  47%|████████▍         | 38/81 [00:08<00:09,  4.63it/s]Loss: 0.4101:  47%|████████▍         | 38/81 [00:08<00:09,  4.63it/s]Loss: 0.4101:  48%|████████▋         | 39/81 [00:08<00:09,  4.64it/s]Loss: 0.4800:  48%|████████▋         | 39/81 [00:09<00:09,  4.64it/s]Loss: 0.4800:  49%|████████▉         | 40/81 [00:09<00:08,  4.64it/s]Loss: 0.5428:  49%|████████▉         | 40/81 [00:09<00:08,  4.64it/s]Loss: 0.5428:  51%|█████████         | 41/81 [00:09<00:08,  4.64it/s]Loss: 0.4779:  51%|█████████         | 41/81 [00:09<00:08,  4.64it/s]Loss: 0.4779:  52%|█████████▎        | 42/81 [00:09<00:08,  4.64it/s]Loss: 0.4636:  52%|█████████▎        | 42/81 [00:09<00:08,  4.64it/s]Loss: 0.4636:  53%|█████████▌        | 43/81 [00:09<00:08,  4.64it/s]Loss: 0.4126:  53%|█████████▌        | 43/81 [00:10<00:08,  4.64it/s]Loss: 0.4126:  54%|█████████▊        | 44/81 [00:10<00:07,  4.65it/s]Loss: 0.5862:  54%|█████████▊        | 44/81 [00:10<00:07,  4.65it/s]Loss: 0.5862:  56%|██████████        | 45/81 [00:10<00:07,  4.65it/s]Loss: 0.5862:  56%|██████████        | 45/81 [00:10<00:07,  4.65it/s]Loss: 0.5862:  57%|██████████▏       | 46/81 [00:10<00:07,  4.65it/s]Loss: 0.5623:  57%|██████████▏       | 46/81 [00:10<00:07,  4.65it/s]Loss: 0.5623:  58%|██████████▍       | 47/81 [00:10<00:07,  4.65it/s]Loss: 0.6018:  58%|██████████▍       | 47/81 [00:10<00:07,  4.65it/s]Loss: 0.6018:  59%|██████████▋       | 48/81 [00:10<00:07,  4.64it/s]Loss: 0.5674:  59%|██████████▋       | 48/81 [00:11<00:07,  4.64it/s]Loss: 0.5674:  60%|██████████▉       | 49/81 [00:11<00:06,  4.64it/s]Loss: 0.5939:  60%|██████████▉       | 49/81 [00:11<00:06,  4.64it/s]Loss: 0.5939:  62%|███████████       | 50/81 [00:11<00:06,  4.63it/s]Loss: 0.5722:  62%|███████████       | 50/81 [00:11<00:06,  4.63it/s]Loss: 0.5722:  63%|███████████▎      | 51/81 [00:11<00:06,  4.64it/s]Loss: 0.4291:  63%|███████████▎      | 51/81 [00:11<00:06,  4.64it/s]Loss: 0.4291:  64%|███████████▌      | 52/81 [00:11<00:06,  4.64it/s]Loss: 0.5060:  64%|███████████▌      | 52/81 [00:11<00:06,  4.64it/s]Loss: 0.5060:  65%|███████████▊      | 53/81 [00:11<00:06,  4.64it/s]Loss: 0.4992:  65%|███████████▊      | 53/81 [00:12<00:06,  4.64it/s]Loss: 0.4992:  67%|████████████      | 54/81 [00:12<00:05,  4.64it/s]Loss: 0.6644:  67%|████████████      | 54/81 [00:12<00:05,  4.64it/s]Loss: 0.6644:  68%|████████████▏     | 55/81 [00:12<00:05,  4.64it/s]Loss: 0.5978:  68%|████████████▏     | 55/81 [00:12<00:05,  4.64it/s]Loss: 0.5978:  69%|████████████▍     | 56/81 [00:12<00:05,  4.61it/s]Loss: 0.5279:  69%|████████████▍     | 56/81 [00:12<00:05,  4.61it/s]2025-03-23 22:25:03,230 - INFO - Step 300: loss = 0.5375
Loss: 0.5279:  70%|████████████▋     | 57/81 [00:12<00:05,  4.61it/s]Loss: 0.5257:  70%|████████████▋     | 57/81 [00:13<00:05,  4.61it/s]Loss: 0.5257:  72%|████████████▉     | 58/81 [00:13<00:04,  4.62it/s]Loss: 0.5653:  72%|████████████▉     | 58/81 [00:13<00:04,  4.62it/s]Loss: 0.5653:  73%|█████████████     | 59/81 [00:13<00:04,  4.63it/s]Loss: 0.5578:  73%|█████████████     | 59/81 [00:13<00:04,  4.63it/s]Loss: 0.5578:  74%|█████████████▎    | 60/81 [00:13<00:04,  4.64it/s]Loss: 0.4981:  74%|█████████████▎    | 60/81 [00:13<00:04,  4.64it/s]Loss: 0.4981:  75%|█████████████▌    | 61/81 [00:13<00:04,  4.64it/s]Loss: 0.5147:  75%|█████████████▌    | 61/81 [00:13<00:04,  4.64it/s]Loss: 0.5147:  77%|█████████████▊    | 62/81 [00:13<00:04,  4.64it/s]Loss: 0.5929:  77%|█████████████▊    | 62/81 [00:14<00:04,  4.64it/s]Loss: 0.5929:  78%|██████████████    | 63/81 [00:14<00:03,  4.64it/s]Loss: 0.6662:  78%|██████████████    | 63/81 [00:14<00:03,  4.64it/s]Loss: 0.6662:  79%|██████████████▏   | 64/81 [00:14<00:03,  4.64it/s]Loss: 0.6409:  79%|██████████████▏   | 64/81 [00:14<00:03,  4.64it/s]Loss: 0.6409:  80%|██████████████▍   | 65/81 [00:14<00:03,  4.64it/s]Loss: 0.6174:  80%|██████████████▍   | 65/81 [00:14<00:03,  4.64it/s]Loss: 0.6174:  81%|██████████████▋   | 66/81 [00:14<00:03,  4.62it/s]Loss: 0.5774:  81%|██████████████▋   | 66/81 [00:15<00:03,  4.62it/s]Loss: 0.5774:  83%|██████████████▉   | 67/81 [00:15<00:03,  4.62it/s]Loss: 0.5134:  83%|██████████████▉   | 67/81 [00:15<00:03,  4.62it/s]Loss: 0.5134:  84%|███████████████   | 68/81 [00:15<00:02,  4.63it/s]Loss: 0.5111:  84%|███████████████   | 68/81 [00:15<00:02,  4.63it/s]Loss: 0.5111:  85%|███████████████▎  | 69/81 [00:15<00:02,  4.63it/s]Loss: 0.4560:  85%|███████████████▎  | 69/81 [00:15<00:02,  4.63it/s]Loss: 0.4560:  86%|███████████████▌  | 70/81 [00:15<00:02,  4.63it/s]Loss: 0.4774:  86%|███████████████▌  | 70/81 [00:15<00:02,  4.63it/s]Loss: 0.4774:  88%|███████████████▊  | 71/81 [00:15<00:02,  4.63it/s]Loss: 0.5321:  88%|███████████████▊  | 71/81 [00:16<00:02,  4.63it/s]Loss: 0.5321:  89%|████████████████  | 72/81 [00:16<00:01,  4.62it/s]Loss: 0.6127:  89%|████████████████  | 72/81 [00:16<00:01,  4.62it/s]Loss: 0.6127:  90%|████████████████▏ | 73/81 [00:16<00:01,  4.62it/s]Loss: 0.5238:  90%|████████████████▏ | 73/81 [00:16<00:01,  4.62it/s]Loss: 0.5238:  91%|████████████████▍ | 74/81 [00:16<00:01,  4.62it/s]Loss: 0.5578:  91%|████████████████▍ | 74/81 [00:16<00:01,  4.62it/s]Loss: 0.5578:  93%|████████████████▋ | 75/81 [00:16<00:01,  4.63it/s]Loss: 0.5172:  93%|████████████████▋ | 75/81 [00:16<00:01,  4.63it/s]Loss: 0.5172:  94%|████████████████▉ | 76/81 [00:16<00:01,  4.63it/s]Loss: 0.4800:  94%|████████████████▉ | 76/81 [00:17<00:01,  4.63it/s]Loss: 0.4800:  95%|█████████████████ | 77/81 [00:17<00:00,  4.64it/s]Loss: 0.5958:  95%|█████████████████ | 77/81 [00:17<00:00,  4.64it/s]Loss: 0.5958:  96%|█████████████████▎| 78/81 [00:17<00:00,  4.64it/s]Loss: 0.5101:  96%|█████████████████▎| 78/81 [00:17<00:00,  4.64it/s]Loss: 0.5101:  98%|█████████████████▌| 79/81 [00:17<00:00,  4.63it/s]Loss: 0.5580:  98%|█████████████████▌| 79/81 [00:17<00:00,  4.63it/s]Loss: 0.5580:  99%|█████████████████▊| 80/81 [00:17<00:00,  4.63it/s]Loss: 0.5196:  99%|█████████████████▊| 80/81 [00:17<00:00,  4.63it/s]Loss: 0.5196: 100%|██████████████████| 81/81 [00:17<00:00,  4.99it/s]Loss: 0.5196: 100%|██████████████████| 81/81 [00:18<00:00,  4.48it/s]
2025-03-23 22:25:08,435 - INFO - Epoch 4 completed. Average loss: 0.5402
2025-03-23 22:25:08,435 - INFO - Running evaluation
Evaluating:   0%|                             | 0/18 [00:00<?, ?it/s]Evaluating:   6%|█▏                   | 1/18 [00:00<00:12,  1.35it/s]Evaluating:  11%|██▎                  | 2/18 [00:00<00:07,  2.24it/s]Evaluating:  17%|███▌                 | 3/18 [00:01<00:05,  2.87it/s]Evaluating:  22%|████▋                | 4/18 [00:01<00:04,  3.27it/s]Evaluating:  28%|█████▊               | 5/18 [00:01<00:03,  3.55it/s]Evaluating:  33%|███████              | 6/18 [00:01<00:03,  3.75it/s]Evaluating:  39%|████████▏            | 7/18 [00:02<00:02,  3.90it/s]Evaluating:  44%|█████████▎           | 8/18 [00:02<00:02,  3.99it/s]Evaluating:  50%|██████████▌          | 9/18 [00:02<00:02,  4.04it/s]Evaluating:  56%|███████████         | 10/18 [00:02<00:01,  4.09it/s]Evaluating:  61%|████████████▏       | 11/18 [00:03<00:01,  4.13it/s]Evaluating:  67%|█████████████▎      | 12/18 [00:03<00:01,  4.15it/s]Evaluating:  72%|██████████████▍     | 13/18 [00:03<00:01,  4.16it/s]Evaluating:  78%|███████████████▌    | 14/18 [00:03<00:00,  4.17it/s]Evaluating:  83%|████████████████▋   | 15/18 [00:04<00:00,  4.18it/s]Evaluating:  89%|█████████████████▊  | 16/18 [00:04<00:00,  4.18it/s]Evaluating:  94%|██████████████████▉ | 17/18 [00:04<00:00,  4.18it/s]Evaluating: 100%|████████████████████| 18/18 [00:04<00:00,  3.85it/s]
2025-03-23 22:25:13,198 - INFO - Eval accuracy: 0.7692307692307693
2025-03-23 22:25:13,198 - INFO - Eval precision: 0.7679585159052477
2025-03-23 22:25:13,198 - INFO - Eval recall: 0.76541971822592
2025-03-23 22:25:13,198 - INFO - Eval f1: 0.7662329205700505
2025-03-23 22:25:13,198 - INFO - Eval precision_entailment: 0.7628504672897196
2025-03-23 22:25:13,198 - INFO - Eval recall_entailment: 0.8091697645600991
2025-03-23 22:25:13,198 - INFO - Eval f1_entailment: 0.7853277209861695
2025-03-23 22:25:13,199 - INFO - Eval precision_neutral: 0.7192429022082019
2025-03-23 22:25:13,199 - INFO - Eval recall_neutral: 0.7113884555382215
2025-03-23 22:25:13,199 - INFO - Eval f1_neutral: 0.7152941176470589
2025-03-23 22:25:13,199 - INFO - Eval precision_contradiction: 0.8217821782178217
2025-03-23 22:25:13,199 - INFO - Eval recall_contradiction: 0.7757009345794392
2025-03-23 22:25:13,199 - INFO - Eval f1_contradiction: 0.7980769230769231
2025-03-23 22:25:14,386 - INFO - Loading tokenizer from: flax-community/indonesian-roberta-base
2025-03-23 22:25:14,858 - INFO - Tokenizer saved successfully to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/epoch-4
2025-03-23 22:25:14,867 - INFO - Model saved to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/epoch-4
2025-03-23 22:25:14,867 - INFO - Epoch 5/5
  0%|                                         | 0/81 [00:00<?, ?it/s]/home/jupyter-23522029/indo-NLI-best-model/src/training/trainer.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Loss: 0.5533:   0%|                           | 0/81 [00:00<?, ?it/s]Loss: 0.5533:   1%|▏                  | 1/81 [00:00<01:18,  1.02it/s]Loss: 0.6153:   1%|▏                  | 1/81 [00:01<01:18,  1.02it/s]Loss: 0.6153:   2%|▍                  | 2/81 [00:01<00:41,  1.89it/s]Loss: 0.5202:   2%|▍                  | 2/81 [00:01<00:41,  1.89it/s]Loss: 0.5202:   4%|▋                  | 3/81 [00:01<00:30,  2.59it/s]Loss: 0.4499:   4%|▋                  | 3/81 [00:01<00:30,  2.59it/s]Loss: 0.4499:   5%|▉                  | 4/81 [00:01<00:24,  3.15it/s]Loss: 0.4727:   5%|▉                  | 4/81 [00:01<00:24,  3.15it/s]Loss: 0.4727:   6%|█▏                 | 5/81 [00:01<00:21,  3.51it/s]Loss: 0.4495:   6%|█▏                 | 5/81 [00:02<00:21,  3.51it/s]Loss: 0.4495:   7%|█▍                 | 6/81 [00:02<00:19,  3.83it/s]Loss: 0.5905:   7%|█▍                 | 6/81 [00:02<00:19,  3.83it/s]Loss: 0.5905:   9%|█▋                 | 7/81 [00:02<00:18,  4.07it/s]Loss: 0.4441:   9%|█▋                 | 7/81 [00:02<00:18,  4.07it/s]Loss: 0.4441:  10%|█▉                 | 8/81 [00:02<00:17,  4.24it/s]Loss: 0.4569:  10%|█▉                 | 8/81 [00:02<00:17,  4.24it/s]Loss: 0.4569:  11%|██                 | 9/81 [00:02<00:16,  4.36it/s]Loss: 0.4016:  11%|██                 | 9/81 [00:02<00:16,  4.36it/s]Loss: 0.4016:  12%|██▏               | 10/81 [00:02<00:15,  4.44it/s]Loss: 0.5096:  12%|██▏               | 10/81 [00:03<00:15,  4.44it/s]Loss: 0.5096:  14%|██▍               | 11/81 [00:03<00:15,  4.49it/s]Loss: 0.4895:  14%|██▍               | 11/81 [00:03<00:15,  4.49it/s]Loss: 0.4895:  15%|██▋               | 12/81 [00:03<00:15,  4.54it/s]Loss: 0.3836:  15%|██▋               | 12/81 [00:03<00:15,  4.54it/s]Loss: 0.3836:  16%|██▉               | 13/81 [00:03<00:14,  4.57it/s]Loss: 0.5511:  16%|██▉               | 13/81 [00:03<00:14,  4.57it/s]Loss: 0.5511:  17%|███               | 14/81 [00:03<00:14,  4.59it/s]Loss: 0.4879:  17%|███               | 14/81 [00:04<00:14,  4.59it/s]Loss: 0.4879:  19%|███▎              | 15/81 [00:04<00:14,  4.61it/s]Loss: 0.4341:  19%|███▎              | 15/81 [00:04<00:14,  4.61it/s]Loss: 0.4341:  20%|███▌              | 16/81 [00:04<00:14,  4.62it/s]Loss: 0.5288:  20%|███▌              | 16/81 [00:04<00:14,  4.62it/s]Loss: 0.5288:  21%|███▊              | 17/81 [00:04<00:13,  4.61it/s]Loss: 0.4241:  21%|███▊              | 17/81 [00:04<00:13,  4.61it/s]Loss: 0.4241:  22%|████              | 18/81 [00:04<00:13,  4.62it/s]Loss: 0.5086:  22%|████              | 18/81 [00:04<00:13,  4.62it/s]Loss: 0.5086:  23%|████▏             | 19/81 [00:04<00:13,  4.63it/s]Loss: 0.5780:  23%|████▏             | 19/81 [00:05<00:13,  4.63it/s]Loss: 0.5780:  25%|████▍             | 20/81 [00:05<00:13,  4.63it/s]Loss: 0.4441:  25%|████▍             | 20/81 [00:05<00:13,  4.63it/s]Loss: 0.4441:  26%|████▋             | 21/81 [00:05<00:12,  4.64it/s]Loss: 0.5378:  26%|████▋             | 21/81 [00:05<00:12,  4.64it/s]Loss: 0.5378:  27%|████▉             | 22/81 [00:05<00:12,  4.64it/s]Loss: 0.4544:  27%|████▉             | 22/81 [00:05<00:12,  4.64it/s]Loss: 0.4544:  28%|█████             | 23/81 [00:05<00:12,  4.64it/s]Loss: 0.4947:  28%|█████             | 23/81 [00:05<00:12,  4.64it/s]Loss: 0.4947:  30%|█████▎            | 24/81 [00:05<00:12,  4.64it/s]Loss: 0.4922:  30%|█████▎            | 24/81 [00:06<00:12,  4.64it/s]Loss: 0.4922:  31%|█████▌            | 25/81 [00:06<00:12,  4.63it/s]Loss: 0.3695:  31%|█████▌            | 25/81 [00:06<00:12,  4.63it/s]Loss: 0.3695:  32%|█████▊            | 26/81 [00:06<00:11,  4.64it/s]Loss: 0.5079:  32%|█████▊            | 26/81 [00:06<00:11,  4.64it/s]Loss: 0.5079:  33%|██████            | 27/81 [00:06<00:11,  4.64it/s]Loss: 0.5483:  33%|██████            | 27/81 [00:06<00:11,  4.64it/s]Loss: 0.5483:  35%|██████▏           | 28/81 [00:06<00:11,  4.64it/s]Loss: 0.4921:  35%|██████▏           | 28/81 [00:07<00:11,  4.64it/s]Loss: 0.4921:  36%|██████▍           | 29/81 [00:07<00:11,  4.64it/s]Loss: 0.5151:  36%|██████▍           | 29/81 [00:07<00:11,  4.64it/s]Loss: 0.5151:  37%|██████▋           | 30/81 [00:07<00:11,  4.62it/s]Loss: 0.4331:  37%|██████▋           | 30/81 [00:07<00:11,  4.62it/s]Loss: 0.4331:  38%|██████▉           | 31/81 [00:07<00:10,  4.62it/s]Loss: 0.4407:  38%|██████▉           | 31/81 [00:07<00:10,  4.62it/s]Loss: 0.4407:  40%|███████           | 32/81 [00:07<00:10,  4.63it/s]Loss: 0.4566:  40%|███████           | 32/81 [00:07<00:10,  4.63it/s]Loss: 0.4566:  41%|███████▎          | 33/81 [00:07<00:10,  4.63it/s]Loss: 0.4861:  41%|███████▎          | 33/81 [00:08<00:10,  4.63it/s]Loss: 0.4861:  42%|███████▌          | 34/81 [00:08<00:10,  4.64it/s]Loss: 0.3527:  42%|███████▌          | 34/81 [00:08<00:10,  4.64it/s]Loss: 0.3527:  43%|███████▊          | 35/81 [00:08<00:09,  4.63it/s]Loss: 0.4867:  43%|███████▊          | 35/81 [00:08<00:09,  4.63it/s]Loss: 0.4867:  44%|████████          | 36/81 [00:08<00:09,  4.63it/s]Loss: 0.4685:  44%|████████          | 36/81 [00:08<00:09,  4.63it/s]Loss: 0.4685:  46%|████████▏         | 37/81 [00:08<00:09,  4.64it/s]Loss: 0.4331:  46%|████████▏         | 37/81 [00:08<00:09,  4.64it/s]Loss: 0.4331:  47%|████████▍         | 38/81 [00:08<00:09,  4.63it/s]Loss: 0.6365:  47%|████████▍         | 38/81 [00:09<00:09,  4.63it/s]Loss: 0.6365:  48%|████████▋         | 39/81 [00:09<00:09,  4.63it/s]Loss: 0.6129:  48%|████████▋         | 39/81 [00:09<00:09,  4.63it/s]Loss: 0.6129:  49%|████████▉         | 40/81 [00:09<00:08,  4.62it/s]Loss: 0.5539:  49%|████████▉         | 40/81 [00:09<00:08,  4.62it/s]Loss: 0.5539:  51%|█████████         | 41/81 [00:09<00:08,  4.63it/s]Loss: 0.5007:  51%|█████████         | 41/81 [00:09<00:08,  4.63it/s]Loss: 0.5007:  52%|█████████▎        | 42/81 [00:09<00:08,  4.63it/s]Loss: 0.4866:  52%|█████████▎        | 42/81 [00:10<00:08,  4.63it/s]Loss: 0.4866:  53%|█████████▌        | 43/81 [00:10<00:08,  4.62it/s]Loss: 0.5056:  53%|█████████▌        | 43/81 [00:10<00:08,  4.62it/s]Loss: 0.5056:  54%|█████████▊        | 44/81 [00:10<00:08,  4.61it/s]Loss: 0.6370:  54%|█████████▊        | 44/81 [00:10<00:08,  4.61it/s]Loss: 0.6370:  56%|██████████        | 45/81 [00:10<00:07,  4.62it/s]Loss: 0.4590:  56%|██████████        | 45/81 [00:10<00:07,  4.62it/s]Loss: 0.4590:  57%|██████████▏       | 46/81 [00:10<00:07,  4.63it/s]Loss: 0.5035:  57%|██████████▏       | 46/81 [00:10<00:07,  4.63it/s]Loss: 0.5035:  58%|██████████▍       | 47/81 [00:10<00:07,  4.64it/s]Loss: 0.6515:  58%|██████████▍       | 47/81 [00:11<00:07,  4.64it/s]Loss: 0.6515:  59%|██████████▋       | 48/81 [00:11<00:07,  4.63it/s]Loss: 0.4624:  59%|██████████▋       | 48/81 [00:11<00:07,  4.63it/s]Loss: 0.4624:  60%|██████████▉       | 49/81 [00:11<00:06,  4.62it/s]Loss: 0.4646:  60%|██████████▉       | 49/81 [00:11<00:06,  4.62it/s]Loss: 0.4646:  62%|███████████       | 50/81 [00:11<00:06,  4.62it/s]Loss: 0.4290:  62%|███████████       | 50/81 [00:11<00:06,  4.62it/s]Loss: 0.4290:  63%|███████████▎      | 51/81 [00:11<00:06,  4.63it/s]Loss: 0.3596:  63%|███████████▎      | 51/81 [00:11<00:06,  4.63it/s]Loss: 0.3596:  64%|███████████▌      | 52/81 [00:11<00:06,  4.63it/s]Loss: 0.5396:  64%|███████████▌      | 52/81 [00:12<00:06,  4.63it/s]Loss: 0.5396:  65%|███████████▊      | 53/81 [00:12<00:06,  4.63it/s]Loss: 0.4941:  65%|███████████▊      | 53/81 [00:12<00:06,  4.63it/s]Loss: 0.4941:  67%|████████████      | 54/81 [00:12<00:05,  4.63it/s]Loss: 0.3861:  67%|████████████      | 54/81 [00:12<00:05,  4.63it/s]Loss: 0.3861:  68%|████████████▏     | 55/81 [00:12<00:05,  4.60it/s]Loss: 0.5160:  68%|████████████▏     | 55/81 [00:12<00:05,  4.60it/s]Loss: 0.5160:  69%|████████████▍     | 56/81 [00:12<00:05,  4.61it/s]Loss: 0.5224:  69%|████████████▍     | 56/81 [00:13<00:05,  4.61it/s]Loss: 0.5224:  70%|████████████▋     | 57/81 [00:13<00:05,  4.61it/s]Loss: 0.4556:  70%|████████████▋     | 57/81 [00:13<00:05,  4.61it/s]Loss: 0.4556:  72%|████████████▉     | 58/81 [00:13<00:04,  4.61it/s]Loss: 0.5282:  72%|████████████▉     | 58/81 [00:13<00:04,  4.61it/s]Loss: 0.5282:  73%|█████████████     | 59/81 [00:13<00:04,  4.62it/s]Loss: 0.5853:  73%|█████████████     | 59/81 [00:13<00:04,  4.62it/s]Loss: 0.5853:  74%|█████████████▎    | 60/81 [00:13<00:04,  4.63it/s]Loss: 0.4704:  74%|█████████████▎    | 60/81 [00:13<00:04,  4.63it/s]Loss: 0.4704:  75%|█████████████▌    | 61/81 [00:13<00:04,  4.60it/s]Loss: 0.5934:  75%|█████████████▌    | 61/81 [00:14<00:04,  4.60it/s]Loss: 0.5934:  77%|█████████████▊    | 62/81 [00:14<00:04,  4.60it/s]Loss: 0.5404:  77%|█████████████▊    | 62/81 [00:14<00:04,  4.60it/s]Loss: 0.5404:  78%|██████████████    | 63/81 [00:14<00:03,  4.61it/s]Loss: 0.5058:  78%|██████████████    | 63/81 [00:14<00:03,  4.61it/s]Loss: 0.5058:  79%|██████████████▏   | 64/81 [00:14<00:03,  4.62it/s]Loss: 0.3602:  79%|██████████████▏   | 64/81 [00:14<00:03,  4.62it/s]Loss: 0.3602:  80%|██████████████▍   | 65/81 [00:14<00:03,  4.62it/s]Loss: 0.3559:  80%|██████████████▍   | 65/81 [00:15<00:03,  4.62it/s]Loss: 0.3559:  81%|██████████████▋   | 66/81 [00:15<00:03,  4.63it/s]Loss: 0.5868:  81%|██████████████▋   | 66/81 [00:15<00:03,  4.63it/s]Loss: 0.5868:  83%|██████████████▉   | 67/81 [00:15<00:03,  4.61it/s]Loss: 0.5506:  83%|██████████████▉   | 67/81 [00:15<00:03,  4.61it/s]Loss: 0.5506:  84%|███████████████   | 68/81 [00:15<00:02,  4.60it/s]Loss: 0.5496:  84%|███████████████   | 68/81 [00:15<00:02,  4.60it/s]Loss: 0.5496:  85%|███████████████▎  | 69/81 [00:15<00:02,  4.60it/s]Loss: 0.5160:  85%|███████████████▎  | 69/81 [00:15<00:02,  4.60it/s]Loss: 0.5160:  86%|███████████████▌  | 70/81 [00:15<00:02,  4.61it/s]Loss: 0.4089:  86%|███████████████▌  | 70/81 [00:16<00:02,  4.61it/s]Loss: 0.4089:  88%|███████████████▊  | 71/81 [00:16<00:02,  4.61it/s]Loss: 0.4261:  88%|███████████████▊  | 71/81 [00:16<00:02,  4.61it/s]Loss: 0.4261:  89%|████████████████  | 72/81 [00:16<00:01,  4.61it/s]Loss: 0.5120:  89%|████████████████  | 72/81 [00:16<00:01,  4.61it/s]Loss: 0.5120:  90%|████████████████▏ | 73/81 [00:16<00:01,  4.60it/s]Loss: 0.4768:  90%|████████████████▏ | 73/81 [00:16<00:01,  4.60it/s]Loss: 0.4768:  91%|████████████████▍ | 74/81 [00:16<00:01,  4.61it/s]Loss: 0.4479:  91%|████████████████▍ | 74/81 [00:16<00:01,  4.61it/s]Loss: 0.4479:  93%|████████████████▋ | 75/81 [00:16<00:01,  4.61it/s]Loss: 0.5390:  93%|████████████████▋ | 75/81 [00:17<00:01,  4.61it/s]2025-03-23 22:25:32,063 - INFO - Step 400: loss = 0.4920
Loss: 0.5390:  94%|████████████████▉ | 76/81 [00:17<00:01,  4.61it/s]Loss: 0.5748:  94%|████████████████▉ | 76/81 [00:17<00:01,  4.61it/s]Loss: 0.5748:  95%|█████████████████ | 77/81 [00:17<00:00,  4.62it/s]Loss: 0.5139:  95%|█████████████████ | 77/81 [00:17<00:00,  4.62it/s]Loss: 0.5139:  96%|█████████████████▎| 78/81 [00:17<00:00,  4.60it/s]Loss: 0.3985:  96%|█████████████████▎| 78/81 [00:17<00:00,  4.60it/s]Loss: 0.3985:  98%|█████████████████▌| 79/81 [00:17<00:00,  4.61it/s]Loss: 0.5049:  98%|█████████████████▌| 79/81 [00:18<00:00,  4.61it/s]Loss: 0.5049:  99%|█████████████████▊| 80/81 [00:18<00:00,  4.61it/s]Loss: 0.5041:  99%|█████████████████▊| 80/81 [00:18<00:00,  4.61it/s]Loss: 0.5041: 100%|██████████████████| 81/81 [00:18<00:00,  4.81it/s]Loss: 0.5041: 100%|██████████████████| 81/81 [00:18<00:00,  4.42it/s]
2025-03-23 22:25:33,191 - INFO - Epoch 5 completed. Average loss: 0.4925
2025-03-23 22:25:33,191 - INFO - Running evaluation
Evaluating:   0%|                             | 0/18 [00:00<?, ?it/s]Evaluating:   6%|█▏                   | 1/18 [00:00<00:12,  1.34it/s]Evaluating:  11%|██▎                  | 2/18 [00:00<00:07,  2.20it/s]Evaluating:  17%|███▌                 | 3/18 [00:01<00:05,  2.81it/s]Evaluating:  22%|████▋                | 4/18 [00:01<00:04,  3.23it/s]Evaluating:  28%|█████▊               | 5/18 [00:01<00:03,  3.50it/s]Evaluating:  33%|███████              | 6/18 [00:01<00:03,  3.70it/s]Evaluating:  39%|████████▏            | 7/18 [00:02<00:02,  3.86it/s]Evaluating:  44%|█████████▎           | 8/18 [00:02<00:02,  3.96it/s]Evaluating:  50%|██████████▌          | 9/18 [00:02<00:02,  4.02it/s]Evaluating:  56%|███████████         | 10/18 [00:02<00:01,  4.06it/s]Evaluating:  61%|████████████▏       | 11/18 [00:03<00:01,  4.10it/s]Evaluating:  67%|█████████████▎      | 12/18 [00:03<00:01,  4.12it/s]Evaluating:  72%|██████████████▍     | 13/18 [00:03<00:01,  4.13it/s]Evaluating:  78%|███████████████▌    | 14/18 [00:03<00:00,  4.14it/s]Evaluating:  83%|████████████████▋   | 15/18 [00:04<00:00,  4.15it/s]Evaluating:  89%|█████████████████▊  | 16/18 [00:04<00:00,  4.16it/s]Evaluating:  94%|██████████████████▉ | 17/18 [00:04<00:00,  4.16it/s]Evaluating: 100%|████████████████████| 18/18 [00:04<00:00,  3.82it/s]
2025-03-23 22:25:37,986 - INFO - Eval accuracy: 0.7637687756030951
2025-03-23 22:25:37,987 - INFO - Eval precision: 0.7615583044305518
2025-03-23 22:25:37,987 - INFO - Eval recall: 0.7606979985593575
2025-03-23 22:25:37,987 - INFO - Eval f1: 0.760999106025532
2025-03-23 22:25:37,987 - INFO - Eval precision_entailment: 0.7681159420289855
2025-03-23 22:25:37,987 - INFO - Eval recall_entailment: 0.7881040892193308
2025-03-23 22:25:37,987 - INFO - Eval f1_entailment: 0.7779816513761468
2025-03-23 22:25:37,987 - INFO - Eval precision_neutral: 0.7074303405572755
2025-03-23 22:25:37,987 - INFO - Eval recall_neutral: 0.7129485179407177
2025-03-23 22:25:37,987 - INFO - Eval f1_neutral: 0.7101787101787101
2025-03-23 22:25:37,987 - INFO - Eval precision_contradiction: 0.8091286307053942
2025-03-23 22:25:37,987 - INFO - Eval recall_contradiction: 0.7810413885180241
2025-03-23 22:25:37,987 - INFO - Eval f1_contradiction: 0.7948369565217391
2025-03-23 22:25:39,203 - INFO - Loading tokenizer from: flax-community/indonesian-roberta-base
2025-03-23 22:25:39,675 - INFO - Tokenizer saved successfully to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/epoch-5
2025-03-23 22:25:39,684 - INFO - Model saved to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/epoch-5
2025-03-23 22:25:40,857 - INFO - Loading tokenizer from: flax-community/indonesian-roberta-base
2025-03-23 22:25:41,331 - INFO - Tokenizer saved successfully to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/final
2025-03-23 22:25:41,340 - INFO - Model saved to /home/jupyter-23522029/indo-NLI-best-model/models/indo-roberta-base/final
2025-03-23 22:25:41,340 - INFO - Training completed!
2025-03-23 22:25:41,413 - INFO - Best evaluation metric: -inf
2025-03-23 22:25:41,414 - INFO - Training completed!
